---
title: "Scientific Paper: Neural Network for Forecasted Avalanche Hazard"
author:
  - name: Brendon Pretorius
    id: PRTBRE007
  - name: Nabil Patel
    id: PTLNAB006
  - name: Nkateko Mawelele
    id: MWLNKA001
  - name: Johan John
    id: JHNJOH010

date: "September 27, 2025"
embed-resources: true
format: 
  html:
    theme: sais-theme.scss
    css: styles.css
    toc: true
    toc-depth: 3
    toc-location: body
    toc-title: "Table of Contents"
---


## Introduction

Avalanche forecasting integrates mountain meteorology, snowpack physics, terrain analysis, and risk communication to reduce loss of life and support safer winter travel. In Scotland, the Scottish Avalanche Information Service (SAIS) publishes daily next-day hazard assessments across six high-mountain regions during winter which draws upon field observations, snowpack tests and weather guidance ([Scottish Avalanche Information Service [SAIS], n.d.](#ref-sais-nd)). This report contributes a data-driven complement to that long-running operational effort. Our task is defined as to construct and evaluate a neural network model that predicts the forecasted avalanche hazard (FAH).

This research isn’t meant to replace expert judgment. It gives forecasters a second opinion that consistently flags risky combinations of weather, terrain, and snowpack variables. In Scotland’s maritime, wind-dominated winters with frequent storm cycles and rapid thaw freeze shifts this kind of decision support sharpens situational awareness and strengthens risk communication ([SAIS, n.d.](#ref-sais-nd); [EAWS, n.d.](#ref-eaws-nd)).

## Background

Scotland’s avalanche forecasts are produced by the Scottish Avalanche Information Service (SAIS). The SAIS conducts daily fieldwork, snow profiles, stability tests and terrain analysis that is blended with meteorological guidance to issue next-day public danger ratings, snowpack summaries and travel advice. This information spans Torridon, Northern Cairngorms, Southern Cairngorms, Creag Meagaidh, Lochaber, and Glencoe. The communication follows the standard EAWS danger scale to keep messages consistent and comparable.

Avalanches are rapid snow flows that can contain ice, rock, and vegetation. The most dangerous to travellers are slab avalanches, where a cohesive slab slides on a weaker layer once shear strength is exceeded by gravitational and external loading. The triggers for an avalanche may be natural (snowfall, wind loading, warming) or manmade (a skier, climber, or snowmobile). These avalanches most often occur on slopes around 34–45 degrees. In Scotland’s maritime, wind-dominated winters wind slabs are common ([Schweizer, Jamieson, & Schneebeli, 2003](#ref-schweizer-2003)).

Avalanche forecasting looks to improving consistency, calibration, and timeliness of hazard assessments which can essentially save lives and reduce societal costs. In Europe, despite substantial growth in backcountry participation, the long-term average annual avalanche fatality count has remained broadly steady at 100 per year across the Alps. This is attributed in part to better education, equipment, and forecasting ([Techel et al., 2016](#ref-techel-2016)). Scotland’s totals are smaller, but fatal and non-fatal involvements recur most winters and SAIS seasonal reports routinely document hundreds of observed avalanches ([SAIS, n.d.](#ref-sais-nd)). The impacts however extend beyond casualty numbers as they tend to disrupt transport, tourism, and emergency services.

## Dataset

The dataset is an operational archive produced by the Scottish Avalanche Information Service (SAIS). It spans approximately fifteen winter seasons and reflects real-time fieldwork. Forecasters collect these records in severe weather environments and under time constraints. As a result, the data shows uneven sampling across storm cycles and regions, along with missing entries during periods of limited access.

The feature set can be categorised into five distinct groups that collectively capture the multifaceted nature of avalanche risk assessment:

**Spatial and Temporal Features** include Date, Area, longitude, latitude, and altitude, which establish the geographical and temporal context of each observation. These variables are crucial for understanding regional variations in avalanche conditions and seasonal patterns across Scotland's diverse mountain terrain.

**Topographical Features** encompass Aspect and Incline, which directly influence avalanche susceptibility. Slope angle determines the gravitational stress on the snowpack, while aspect affects wind loading, solar exposure, and temperature variations that influence snow stability.

**Meteorological Features** comprise a comprehensive set of weather observations including air temperature, wind direction and speed (both at observation level and summit), cloud cover, precipitation codes, and insolation. These variables capture the atmospheric conditions that drive snow accumulation, redistribution, and metamorphism processes fundamental to avalanche formation.

**Snowpack Physical Properties** include total snow depth, foot and ski penetration measurements, snow temperature, crystal characteristics, wetness levels, and drift indicators. These features provide direct measures of snowpack structure, density, and mechanical properties that determine stability and failure potential.

**Snowpack Stability Indicators** encompass specialised measurements such as temperature and hardness gradients, settlement patterns, and composite indices like Snow.Index and AV.Cat. These derived metrics capture the complex internal structure and stress distribution within the snowpack that directly relate to avalanche hazard assessment [@anthropic2024claude].

By relating these predictors to FAH the model can learn recurrent, non-linear patterns. It highlights situations where higher hazard is more likely, so forecasters can focus their checks and make cleaner day-to-day calls ([EAWS, n.d.](#ref-eaws-nd); [SAIS, n.d.](#ref-sais-nd)).

## Methodology

This solution developed a supervised neural network classifier to predict next-day FAH using 16 years of SAIS operational data. The methodology followed a systematic machine learning pipeline implemented in R with reproducibility ensured through fixed random seeds.

The dataset underwent comprehensive exploratory data analysis to assess missing data patterns, outlier distributions, and class imbalances. Non-predictive variables (observed avalanche hazard, observer identifiers, and location codes) were removed to prevent data leakage. Observations with missing target values were excluded, and FAH categories were standardized into five ordinal risk levels: Low, Moderate, Considerable-, Considerable+, and High. Statistical outlier detection using the interquartile range method combined with domain-specific constraints removed physically implausible values while preserving legitimate extreme weather events.

New meteorologically meaningful variables were created, including wind chill indices, temperature gradients, snow-altitude interactions, and trigonometric aspect transformations. Temporal features (month, day of year, season) captured seasonal avalanche patterns. A multi-method feature selection approach combined LASSO regularisation, Random Forest importance scoring, and correlation analysis to identify the 25 most predictive variables using weighted composite scores.

The dataset was split into training (70%), validation (15%), and test (15%) sets using stratified sampling to maintain class proportions. To address severe class imbalance (original ratio 7.2:1), the Random Over-Sampling Examples (ROSE) technique was applied exclusively to training data using a one-versus-rest strategy, reducing imbalance to approximately 1.2:1 while preserving natural distributions in evaluation sets.

A three-layer deep neural network was implemented using Keras/TensorFlow with progressive layer sizes (256→128→64 neurons), batch normalization for training stability, and dropout regularization (rates: 0.3, 0.4, 0.5) to prevent overfitting. The model employed categorical crossentropy loss with Adam optimization and incorporated Gaussian noise injection for additional regularisation. Hyperparameter tuning evaluated three configurations, selecting the optimal based on validation accuracy.

The final model was trained for up to 150 epochs with early stopping and learning rate reduction callbacks. Evaluation employed both standard multiclass metrics (accuracy, precision, recall, F1-score) and ordinal-specific measures including adjacent accuracy (±1 level), mean absolute error, and safety-critical metrics such as conservative bias and critical miss rates. This comprehensive evaluation framework assessed both predictive performance and operational safety implications for avalanche forecasting.

We used large language models (LLMs) to accelerate routine coding tasks. Each team member supplied an LLM with a structured brief (data schema, variable descriptions, target definition, leakage constraints, evaluation metrics) to draft boilerplate R code for preprocessing, imputation functions, model scaffolding (keras3), and plotting. To promote diversity of ideas and reduce single-model bias, different teammates intentionally used different LLMs. This use of LLMs sped up drafting, but final code, methodological choices, and validation remained human-curated. Our detailed statement on the use of generative artifical intelligence (AI) is included in [LLM Usage and Reflection](llm-reflection.html). In the next section, we initiated exploratory data analysis (EDA) before developing our model. 

## Exploratory Data Analysis

This section of the report examines the key characteristics of the Scottish avalanche forecast dataset to inform modeling decisions and identify potential challenges. In particular, it investigates the distribution and balance of the target variable (FAH), assesses missing data patterns across all variables to guide preprocessing strategies, and explores temporal coverage to understand seasonal patterns and data collection consistency. 

### Target Variable Distribution

This section examines the distribution of our target variable (FAH) to understand class balance and identify potential modeling challenges that arise from the natural rarity of high-risk avalanche conditions.

![FAH Distribution](../R work/Graphs/fig2.jpg){#fig-target-pie fig-cap="Pie chart of FAH distribution"}

From @fig-target-pie, we observe that the FAH target variable exhibits severe class imbalance, with safer classes dominating the distribution: Low and Moderate together account for approximately 63% of observations, while Considerable- is moderately represented at 23.6%. In contrast, the higher-risk classes i.e., Considerable+ and especially High are rare. This skew implies that a model could achieve high overall accuracy by favoring common classes i.e., naive classification, while failing to detect infrequent but critical high-hazard events. To mitigate this, we later employ ROSE balancing.

### Missing Data Analysis

This section assesses missing data patterns across all variables to identify problematic predictors and inform data quality decisions for preprocessing.

![Missing data analysis graph](../R work/Graphs/fig3.jpg){#fig-missing-data fig-cap="Missing data analysis"}

From @fig-missing-data, the missing data diagnostics reveal that **AV_Cat** and **Ski_Pen** exhibit the highest gaps (≈20%+), prompting their removal from the dataset during preprocessing. Following these, a cluster of snowpack microstructure and condition variables (e.g., Crystals, Wetness, No Settle) show moderate missingness, alongside certain wind-direction and temperature fields. Therefore, we implemented data imputation techniques to account for the missing data in these features. The target variable FAH has negligible missingness; however, we removed observations with missing data in the target variable.

### Data Quality Issues & Outliers

Our outlier analysis during EDA revealed significant data quality issues across multiple features. Altitude measurements contained two extreme outliers (244,859m and 77,044m) that were physically impossible given Scotland's topography, where the highest peak reaches only 1,345m. Aspect measurements included values exceeding 163,770 degrees, far beyond the valid compass range of 0-360 degrees. Wind speed data exhibited a broad range from negative values to 290 km/h, with summit wind speeds reaching up to 360 km/h—values that likely represent measurement errors rather than genuine hurricane-force conditions in Scottish mountains. Snow depth measurements displayed extreme variability, ranging from negative values to an implausible maximum of 3,000cm (30 metres), significantly exceeding typical Scottish mountain snow accumulation patterns. Cloud cover data contained impossible values, including negative percentages and readings up to 199%, exceeding the theoretical maximum of 100%. Both foot and ski penetration measurements included negative values, with foot penetration ranging up to 300cm and ski penetration reaching 55cm. Incline data spanned from negative values to 1,020 degrees, with numerous observations exceeding 90 degrees. Extreme values were addressed through a combination of IQR-based removal for most variables and domain-specific thresholds for others, with negative values corrected to zero and upper limits applied based on physical plausibility within the Scottish mountain context.

### Temporal Analysis

This section examines the temporal distribution of observations to understand seasonal patterns, data collection consistency, and potential time-based features for modeling.

![Temporal analysis graphs](../R work/Graphs/fig4.jpg){#fig-temporal-coverage fig-cap="Temporal analysis"}

From @fig-temporal-coverage, it can be observed that the dataset spans from 2009 to 2025, providing 16 years of avalanche forecasting data with remarkable consistency. The monthly distribution reveals the expected strong seasonal concentration, with the vast majority of observations occurring during winter months (December through March).  Summer months (May through November) show minimal or zero activity, which aligns perfectly with avalanche season expectations in Scottish mountains where snow conditions are primarily a winter phenomenon. These temporal patterns supported the inclusion of seasonal and monthly features in our neural network model, as demonstrated in the feature engineering section [Feature Engineering](#sec-feature-engineering). 

### Comparison of Actual and Predicted Observations

This section evaluates the relationship between forecast and observed avalanche hazard levels to establish baseline performance expectations and identify inherent prediction challenges.

![Graph comparing FAH versus OAH pairs](../R work/Graphs/fig5.jpg){#fig-fah-oah fig-cap="Graph comparing FAH versus OAH pairs"}

From @fig-fah-oah, which analyses FAH versus OAH pairs as a verification benchmark for forecast reliability, we observe an overall accuracy of approximately 70–75%. Per-class performance varies notably: accuracy is highest for Low risk (mid-90s%), followed by Moderate (70%), then decreases for Considerable- (60–70%), drops substantially for Considerable+ (35%), and improves slightly for High (~45%). This pattern suggests that forecasters—and by extension, predictive models—struggle most with distinguishing adjacent hazard boundaries. Accordingly, our model evaluation emphasises ordinal metrics such as adjacent accuracy (±1 level), critical-miss rate (underpredicting high risk), and high-risk sensitivity to ensure practical utility in avalanche forecasting.

### Correlation analysis

This section evaluates the correlations between the features as well as the correlations between the features and the output.

![Correlation heatmap](../R work/Graphs/fig6.jpg){#fig-correlation-heatmap fig-cap="Correlation heatmap"}

The correlation heatmap in @fig-correlation-heatmap reveals coherent but mostly moderate correlation clusters among variables. Notably, temperature features (Air temperature, and summit air temperature) exhibit strong covariation, while cloud and insolation show the expected inverse relationship. Wind speeds correlate across levels with some directional noise, and penetration/strength metrics (Foot penetration and ski penetration depth) associate with total snow depth in predictable ways. Meanwhile, maximum temperature gradient and maximum hardness gradient relate to temperature and snow-structure variables through more complex mechanisms, likely tied to metamorphic processes in the snowpack. Overall, this indicates potential multicollinearity, particularly among thermodynamic and wind features, which could destabilise linear models and hinder neural network convergence. To address this, we implemented ensemble feature selection combining LASSO regularisation, random forest importance scoring, and correlation-based filtering to minimise redundancy.

### EDA Conclusion

The target variable (FAH) exhibits severe class imbalance, with safer conditions (Low and Moderate) dominating approximately 63% of observations whilst higher-risk categories (Considerable+ and High) remain rare.  To address this imbalance, ROSE sampling was applied to the training data using a one-versus-rest strategy, generating synthetic samples to achieve more balanced class distributions whilst preserving natural distributions in validation and test sets. Missing data patterns reveal structured gaps rather than random missingness. Variables **AV.Cat** and **Ski.Pen** show the highest missingness rates (>20%), prompting their removal during preprocessing. Additional moderate gaps appear in snowpack microstructure variables and certain meteorological fields, leading to the implementation of imputation strategies for missing data. The temporal analysis confirms expected seasonal patterns, with observations concentrated heavily in winter months (December-March) across a consistent 16-year span from 2009-2025. This seasonal clustering directly motivated the creation of temporal features including month, day of year, and season variables, whilst the stable annual collection volumes validate the dataset's temporal consistency for model training. Forecast verification analysis comparing FAH versus OAH reveals overall accuracy of approximately 70-75%, with performance varying substantially across risk levels. Accuracy peaks for Low risk conditions (mid-90s%) but deteriorates progressively through higher-risk categories, reaching lowest levels for Considerable+ (35%). This pattern highlights the inherent difficulty in distinguishing adjacent hazard boundaries, directly informing the adoption of ordinal-specific evaluation metrics including adjacent accuracy (±1 level), critical miss rates, and high-risk sensitivity measures rather than relying solely on overall classification accuracy. The following section discusses our data refinement stategy.

## Data Refinement

The raw Scottish avalanche forecast dataset required systematic preprocessing to ensure reliable neural network training whilst preserving the meteorological and topographical signals essential for hazard prediction. Our data refinement approach balanced the competing demands of maintaining data integrity and achieving computational tractability, recognising that avalanche conditions exhibit strong spatial and temporal dependencies that must be preserved throughout the cleaning process.  The following subsections detail our systematic approach to feature removal, outlier detection, feature engineering, missing value imputation, target encoding, feature selection, and class balancing, culminating in a refined dataset of 7,530 complete observations suitable for robust neural network training and evaluation.

### Feature Removal

Our preprocessing commenced with the removal of non-predictive administrative fields, specifically OAH (observed avalanche hazard) and Obs (observer identifier), since our objective focused on predicting forecasted rather than observed conditions. In addition, after the imputation section, we removed non-predictive features i.e., **Date**, **OSgrid** and **location**. 

We eliminated 109 observations lacking FAH values, leaving 10 562 viable records. Missing data analysis exposed significant gaps in **AV.Cat** (23.4%) and **Ski.Pen** (22.5%), which we excluded to avoid unreliable imputation. The remaining variables exhibited structured rather than random missingness patterns, with core meteorological and topographical measurements showing minimal gaps (≤3%), supporting our subsequent contextual imputation approach. 

### Outlier Removal

Our outlier removal strategy involved a dual-tier outlier detection protocol compining statistical principles with domain expertise. Initially, we converted string representations of missing values to proper NA indicators and applied robust Interquartile Range filtering (with a swift scalar parameter of k=3.5) to meteorological variables prone to measurement errors i.e.:
 
- **Alt** (2) 
- **Wind.Speed** (22)
- **Summit.Wind.Speed** (81) 
- **Total.Snow.Depth** (111) 
- **Air.Temp** (1)  
- **Foot.Pen** (34) 

Subsequently, we enforced physical plausibility constraints, removing Aspect measurements exceeding 360 degrees (8 cases), constraining Cloud coverage to 0-100% (3 cases), and limiting Incline to physically realistic slopes between 0-90 degrees (5 cases). This conservative approach eliminated 267 observations (2.53% of the dataset) whilst preserving legitimate extreme weather events that provide crucial signal for hazard prediction. The methodology successfully removed erroneous readings that would distort feature scaling and hinder neural network optimisation, without sacrificing valuable information about genuine storm conditions.

### Feature Engineering {#sec-feature-engineering}

We developed five engineered features that encode avalanche formation mechanisms directly into the predictor space. Wind chill, calculated as air temperature minus 0.6 times wind speed, approximates near-surface cooling effects that influence snowpack stability under windy conditions. Temperature gradient, representing the difference between summit air temperature and air temperature, captures atmospheric stability and potential for snow transport processes. Snow altitude interaction  multiplies total snow depth by altitude scaled to kilometres, reflecting elevation-dependent snow accumulation patterns and rain-snow transition zones. Recognising the circular nature of compass bearings, we transformed aspect into orthogonal components i.e., aspect north using cosine transformation and aspect east using sine transformation, eliminating artificial discontinuities at 360° and 0°. Temporal features i.e., Month, day, and season were extracted to capture the pronounced seasonal patterns evident in the EDA, enabling the network to learn both inter- and intra-seasonal risk variations.

### Imputation for Missing Values

Missing value imputation employed a hierarchical approach reflecting the spatial and temporal structure of avalanche conditions. We employed area and seasonal medians to impute missing values in numerical features, while categorical features were imputed using modal values.  This ensures replacement values reflect typical conditions for specific regions and seasons rather than dataset-wide averages that could misrepresent local climate patterns.

### Encoding

The next step in our model involved encoding encoded categorical features and the target variable. Target encoding transformed the categorical FAH variable into an ordinal integer sequence (Low=0, Moderate=1, Considerable-=2, Considerable+=3, High=4), preserving the natural risk hierarchy essential for ordinal classification evaluation. For predictors, we cleaned categorical fields and applied a frequency threshold (≥50) so very rare levels were folded into “Other” to limit sparsity. 

### Feature Selection

The model implements a comprehensive feature selection process. The process begins by separating features from the target variable and standardising numerical features using centre and scale normalisation to ensure all variables are on comparable scales. The model employs a multi-method approach that combines three different feature selection techniques to create a robust scoring framework. First, it uses LASSO regularisation with cross-validation to identify features with non-zero coefficients, scoring them based on the absolute magnitude of their coefficients. Second, it applies Random Forest to evaluate feature importance, though it limits the analysis to the top 50 most correlated features if the dataset is too large. Finally, it calculates correlation-based scores by measuring the absolute correlation between each feature and the target variable.

The innovative aspect of this approach lies in its composite scoring system, which weights each method's contributions (LASSO 30%, Random Forest 40%, and correlation 30%) and provides a bonus for features that perform well across multiple methods. Features selected by more methods receive higher total scores through a multiplicative bonus factor. The process concludes by ranking all features according to their composite scores and selecting the top 25 features for subsequent modelling. This methodology ensures that the selected features are not only individually predictive but also consistently identified across different selection techniques, potentially leading to more robust model performance.

### Stratified Splitting and Class Balance Correction

The refined dataset of 7 530 observations underwent stratified partitioning to maintain proportional class representation across training (70%, 5,273 samples), validation (15%, 1,129 samples), and test (15%, 1,128 samples) sets. This preserved the natural class imbalance for realistic evaluation whilst ensuring adequate representation of each hazard level.

Class imbalance in the training set showed a severe 12.4:1 ratio between majority and minority classes, necessitating corrective sampling. We applied ROSE exclusively to training data post-split to prevent data leakage, using an iterative one-versus-rest strategy to accommodate ROSE's binary classification requirement. Synthetic samples were generated for minority classes until reaching approximately 95% of majority class size, avoiding perfect balance that might introduce artificial patterns.

The enhanced training set expanded from 5,273 to 8,641 observations with roughly 1,700 samples per class, reducing imbalance to 1.05:1 (91.5% improvement). This substantial rebalancing provides the neural network with sufficient minority class examples for effective learning whilst maintaining natural class distributions in validation and test sets for unbiased performance evaluation.

### Neural Network Architecture

After hyperparameter tuning across three candidate configurations, the optimal network achieved a validation accuracy of 0.6138 with a corresponding training accuracy of 0.7159. This represented the best trade-off between learning capacity and generalisation. The final architecture consisted of three hidden layers with 512, 256, and 128 units, respectively, paired with progressively increasing dropout regularisation (0.20, 0.30, 0.40). Gaussian noise was applied at the input layer to mitigate overfitting and improve robustness against noisy environmental predictors. The network was trained using the Adam optimiser with a learning rate of 5×10⁻⁴ and a batch size of 32, which provided stable convergence during training.

| Layer          | Units | Dropout | Notes                             |
|----------------|-------|---------|-----------------------------------|
| Input          | –     | –       | 25 selected features              |
| Hidden Layer 1 | 512   | 0.20    | Dense + BatchNorm + GaussianNoise |
| Hidden Layer 2 | 256   | 0.30    | Dense + BatchNorm + Dropout       |
| Hidden Layer 3 | 128   | 0.40    | Dense + BatchNorm + Dropout       |
| Output         | 5     | –       | Softmax (multiclass, ordinal)     |

*Table 1: Final neural network architecture*

The training and validation curves showed that the model achieved stable convergence, though validation accuracy plateaued around 0.61, reflecting the intrinsic difficulty of predicting the rare high-risk classes.

## Model Performance Evaluation

### Overall Performance

The neural network’s performance was assessed across the training, validation, and test datasets to evaluate both its learning capacity and generalisation ability. During training, the model achieved a best training accuracy of 71.6%, with the corresponding best validation accuracy reaching 61.4%. The final test accuracy was 60.6% (loss = 0.993). The gap between training and validation performance indicates some overfitting, which is expected in complex models, but the close alignment of validation and test results shows that the network generalised reasonably well to unseen data and avoided substantial performance degradation. 

Beyond test accuracy, complementary metrics provided deeper insight into generalisation. Macro-averaged scores (precision = 0.499, recall = 0.452, F1 = 0.459) showed that the model was only moderately effective when treating all classes equally. Weighted averages were higher (precision = 0.589, recall = 0.606, F1 = 0.594), reflecting stronger performance on the dominant classes. Cohen’s Kappa, at 0.443, placed the model in the “moderate agreement” range, showing that predictions were significantly better than random guessing but not yet highly reliable. EDA findings again provide explanation: the removal of several snowpack variables with >20% missingness reduced the depth of predictive features, while extreme but plausible outliers (e.g., very high winds, deep snowpack events) complicated the learning process, particularly for rarer hazard categories.

Given the ordinal nature of avalanche hazard levels, error magnitudes were as important as raw accuracy. Predictions deviated by an average of only 0.45 hazard levels (MAE), with relatively low dispersion (RMSE = 0.765; MSE = 0.585). Adjacent accuracy was exceptionally high (94.5% within ±1 level), while extreme misclassifications were nearly absent (99.5% within ±2 levels; 100% within ±3 levels). These findings confirm that catastrophic errors (e.g., predicting Low when the true level was High) were virtually eliminated. This aligns with EDA evidence showing that extreme meteorological conditions such as heavy snowfall or very strong winds rarely overlapped with Low hazard conditions, providing the model with clearer separation at the extremes.

Finally, correlation-based metrics confirmed that the network preserved the ordinal structure of avalanche hazard levels. Strong monotonic associations were observed (Spearman’s ρ = 0.738, Pearson r = 0.723), with Kendall’s Tau (0.670, p < 0.001) and directional accuracy (0.718) showing that the ordering of predicted hazard levels was largely consistent with the true sequence. Together, these results show that while the model achieved only moderate exact-match classification accuracy, it maintained ordinal consistency, avoided severe misclassifications, and delivered meaningful improvements over baseline predictors.

| Metric                         | Value   |
|--------------------------------|---------|
| Training Accuracy              | 0.716   |
| Validation Accuracy            | 0.614   |
| Test Accuracy                  | 0.606   |
| Test Loss                      | 0.993   |
| Macro Precision                | 0.499   |
| Macro Recall                   | 0.452   |
| Macro F1-Score                 | 0.459   |
| Weighted Precision             | 0.589   |
| Weighted Recall                | 0.606   |
| Weighted F1-Score              | 0.594   |
| Cohen’s Kappa                  | 0.443   |
| Mean Absolute Error (MAE)      | 0.454   |
| Root Mean Squared Error (RMSE) | 0.765   |
| Mean Squared Error (MSE)       | 0.585   |
| Adjacent Accuracy (±1 level)   | 0.945   |
| Within-2 Accuracy (±2 levels)  | 0.995   |
| Within-3 Accuracy (±3 levels)  | 1.000   |
| Spearman’s ρ                   | 0.738   |
| Pearson r                      | 0.723   |
| Kendall’s Tau                  | 0.670   |
| Directional Accuracy           | 0.718   |

*Table 2: Overall Performance Metrics of the Neural Network*

### Confusion Matrix and Class-Level Performance

The confusion matrix offered a clear breakdown of how the model performed across individual hazard levels. For the Low hazard class, the network achieved strong results (sensitivity = 0.836, precision = 0.723, F1 = 0.775), reflecting consistent identification of stable snowpack conditions. This strength is consistent with EDA findings, which showed that Low days were associated with distinct signals — shallow snow depth, weak drift, and stable temperature gradients — making them easier for the model to separate. Similarly, the Moderate class reached moderate reliability (sensitivity = 0.540, precision = 0.578, F1 = 0.558), supported by its high prevalence in the dataset and relatively consistent meteorological profiles. Together, these two classes accounted for most correct predictions, reflecting both their dominance in the dataset and their clearer predictor signatures.

The Considerable– class performed less consistently (precision = 0.526, recall = 0.553, F1 = 0.539). Misclassifications were concentrated between adjacent levels: 79 cases confused with Moderate and 20 with Considerable+. This behavior aligns with the transitional nature of predictors highlighted in the EDA, where snow depth, crystal type, and summit air temperature overlapped substantially between Moderate and Considerable– categories.

Performance deteriorated sharply for the Considerable+ and High hazard levels, which achieved very low recall (0.241 and 0.091, respectively) and correspondingly low F1-scores (0.280 and 0.143). High cases were most often misclassified as Considerable– (14 cases) or Considerable+ (15 cases), but crucially, none were mistaken for Low. This indicates that while the model struggled to distinguish among upper hazard levels, it preserved ordinal structure and avoided catastrophic misclassifications. The EDA findings explain this limitation: these rare categories comprised less than 5% of the dataset and were characterised by overlapping meteorological signals such as heavy snowfall, wind drift, and deep weak layers. With limited training samples, the network could not fully disentangle these patterns.

The per-class F1-scores reflected this gradient in performance: Low (0.775) and Moderate (0.558) were acceptable, Considerable– was moderate (0.539), while Considerable+ (0.280) and High (0.143) were poor. These values highlight the central trade-off of the model: strong utility in predicting stable and moderately unstable conditions, but weak reliability in capturing rare but operationally critical high-risk categories.

| Predicted \ Actual | Low | Moderate | Considerable – | Considerable + | High |
|--------------------|-----|----------|----------------|----------------|------|
| Low                | 315 | 105      | 11             | 5              | 0    |
| Moderate           | 55  | 205      | 79             | 15             | 1    |
| Considerable –     | 7   | 65       | 141            | 41             | 14   |
| Considerable +     | 0   | 5        | 20             | 20             | 15   |
| High               | 0   | 0        | 4              | 2              | 3    |

*Table 3: Confusion Matrix of Predicted vs Actual Avalanche Hazard Levels*

| Class           | Precision | Recall | F1-Score | Support |
|-----------------|-----------|--------|----------|---------|
| Low             | 0.723     | 0.836  | 0.775    | 377     |
| Moderate        | 0.578     | 0.540  | 0.558    | 380     |
| Considerable –  | 0.526     | 0.553  | 0.539    | 255     |
| Considerable +  | 0.333     | 0.241  | 0.280    | 83      |
| High            | 0.333     | 0.091  | 0.143    | 33      |

*Table 4: Precision, Recall, and F1-Score by Avalanche Hazard Class*



### Confidence-Based Reliability

Most predictions were made with low confidence (≤0.6, 62.9%), while 23.0% were medium (0.6–0.8) and only 14.1% were high (>0.8). Prediction accuracy scaled with confidence: 88.7% at high confidence, 65.3% at medium, and 52.7% at low confidence. At the class level, Low hazard predictions averaged the highest confidence (0.708) with strong accuracy (83.6%), while Moderate (0.551) and Considerable– (0.511) showed low confidence and middling reliability.Predictions for Considerable+ (0.527) and High (0.584) carried similarly low confidence but were far less accurate (24.1% and 9.1%, respectively), highlighting systematic difficulty with rare high-risk categories. These results confirm that prediction probabilities provided a meaningful gradient of reliability, with higher confidence strongly associated with higher accuracy.

| Confidence Level   | Accuracy |
|--------------------|----------|
| High (> 0.8)       | 88.7%    |
| Medium (0.6–0.8)   | 65.3%    |
| Low (≤ 0.6)        | 52.7%    |

*Table 5: Accuracy of Predictions by Confidence Level*


| Confidence Level   | Accuracy |
|--------------------|----------|
| High (> 0.8)       | 88.7%    |
| Medium (0.6–0.8)   | 65.3%    |
| Low (≤ 0.6)        | 52.7%    |

*Table 6: Accuracy of Predictions by Confidence Level*



### Avalanche-Specific Safety Metrics

The model achieved a Critical Miss Rate of 18.1%, showing that nearly one in five severe avalanche cases (Considerable+ or High) were underestimated as Low or Moderate. Safety Effectiveness reached 74.6%, indicating that in most cases the model predicted at or above the true hazard level. A negative Conservative Bias (–0.114) revealed a mild tendency to underestimate risk overall. High-risk detection showed mixed outcomes: Sensitivity was 70.1%, meaning most but not all severe cases were detected, while Specificity was 89.8%, reflecting strong reliability in avoiding false alarms.

| Metric                   | Value   | Interpretation                                      |
|--------------------------|---------|-----------------------------------------------------|
| Critical Miss Rate       | 18.1%   | Severe events underestimated as Low/Moderate        |
| Safety Effectiveness     | 74.7%   | Predictions at or above true hazard level           |
| Conservative Bias        | –0.114  | Mild overall tendency to underestimate risk         |
| High-Risk Sensitivity    | 70.1%   | Ability to detect Considerable– and above           |
| High-Risk Specificity    | 89.8%   | Ability to avoid false alarms on lower-risk levels  |

*Table 7: Avalanche-Specific Safety Metrics*


## Feature Importance Assessment

The feature importance analysis revealed that predictors strongly aligned with established avalanche science and EDA findings. Foot Penetration and Drift were the top-ranked features, reflecting their direct links to snowpack weakness and wind-driven slab formation. Key atmospheric drivers — Summit Air Temperature and Total Snow Depth — also ranked highly, confirming their influence on hazard variability observed in the EDA. Crystal Type added further insight into snow microstructure transitions, especially between Moderate and Considerable– categories.

Wind- and temperature-related factors such as Air Temperature, Wind Chill, and Wind Speed consistently scored highly across methods, echoing EDA findings on strong thermal gradients and wind redistribution as critical instability drivers. Seasonal and temporal features — particularly Winter, Day of Year, and Snow–Altitude Interaction — captured the clustering of high hazard levels during winter peaks and at higher elevations. Geographical indicators such as Lochaber and Torridon added spatial context, though with secondary importance.

In summary, the most important features reflected a combination of snowpack properties, meteorological drivers, and seasonal patterns, confirming that the model’s predictive behaviour was rooted in meaningful physical processes identified during the exploratory analysis.

![Feature importance graphs](../R work/Graphs/fig7.jpg){#fig-feature-importance fig-cap="Feature importance graphs"}

## Conclusion and Recommendations

This study evaluated the application of a neural network model to forecast avalanche hazard levels in Scotland, integrating exploratory data analysis, feature engineering, and rigorous model evaluation.The neural network achieved a training accuracy of 71.6%, a validation accuracy of 61.4%, and a test accuracy of 60.6%, showing good generalisation without major overfitting. While exact classification accuracy was moderate, 94.5% of predictions were within ±1 hazard level, and errors averaged only 0.45 levels, indicating that the model preserved ordinal structure and avoided large-scale misclassifications. Performance was strongest for Low and Moderate hazards but much weaker for rare severe levels (Considerable+ and High), reflected in a Critical Miss Rate of 18.1% and a Safety Effectiveness of 74.6%

Feature importance confirmed that avalanche risk was primarily driven by snowpack properties (Foot Penetration, Snow Depth, Crystal Type), wind-related processes (Drift, Wind Chill, Wind Speed), and temperature gradients (Summit Air Temperature, Air Temperature), alongside seasonal and regional influences.

To improve performance, future work should focus on better representation of high-hazard cases, possibly through expanded datasets or transfer learning. Ensemble methods and uncertainty-based outputs could also increase operational reliability. While not yet suitable as a standalone system, the model shows strong potential as a decision-support tool when combined with expert judgment.


## Author Contributions
- Brendon Pretorius: Formal Analysis, Project Administration, Writing – Review & Editing
- Johan John: Formal Analysis, Writing – Original Draft Preparation
- Nabil Patel: Formal Analysis, Methodology, Writing – Original Draft Preparation
- Nkateko Mawelele: Formal Analysis, Writing – Original Draft Preparation  

## References (APA)

<a id="ref-bishop-2006"></a>Bishop, C. M. (2006). *Pattern recognition and machine learning*. Springer.

<a id="ref-anthropic2024claude"></a>Anthropic. (2024). *Claude Sonnet 4 (December 28 version)* [Large language model]. https://claude.ai/chat

<a id="ref-eaws-nd"></a>European Avalanche Warning Services. (n.d.). *Danger scale and standards*. https://www.avalanches.org

<a id="ref-goodfellow-2016"></a>Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep learning*. MIT Press.

<a id="ref-juvik-2023"></a>Juvik, E. S. (2023). Toward data-driven decision support for avalanche-exposed roads in Norway. In *Proceedings of the International Snow Science Workshop* (ISSW 2023). Norwegian Public Roads Administration.

<a id="ref-mcclung-2006"></a>McClung, D., & Schaerer, P. (2006). *The avalanche handbook* (3rd ed.). The Mountaineers Books.

<a id="ref-sais-nd"></a>Scottish Avalanche Information Service. (n.d.). *About SAIS and daily avalanche reports*. https://www.sais.gov.uk

<a id="ref-schweizer-2003"></a>Schweizer, J., Jamieson, B., & Schneebeli, M. (2003). Snow avalanche formation. *Reviews of Geophysics, 41*(4), 1–25. https://doi.org/10.1029/2002RG000123

<a id="ref-techel-2014"></a>Techel, F., & Zweifel, B. (2014). Recreational avalanche accidents in Switzerland: Trends and patterns with an emphasis on burial, rescue methods and avalanche danger. *Cold Regions Science and Technology, 97*, 77–85. https://doi.org/10.1016/j.coldregions.2013.09.006

<a id="ref-techel-2016"></a>Techel, F., Jarry, F., Kronthaler, G., Mitterer, C., Nairz, P., Pavšek, M., Valt, M., & Zweifel, B. (2016). Avalanche fatalities in the European Alps: Long-term trends and perspectives. *Cold Regions Science and Technology, 121*, 22–31. https://doi.org/10.1016/j.coldregions.2015.11.017