[
  {
    "objectID": "paper.html",
    "href": "paper.html",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "[REPORT]"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA5073Z Assignment 1: Avalanche Hazard Prediction",
    "section": "",
    "text": "Welcome to our Avalanche Hazard Prediction project.\n- Scientific Paper\n- LLM Reflection"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "llm-reflection.html",
    "href": "llm-reflection.html",
    "title": "LLM Usage and Reflection",
    "section": "",
    "text": "Our group extensively utilized multiple artificial intelligence tools throughout this avalanche prediction neural network project, employing a systematic and transparent approach to AI integration. The tools included Claude (Sonnet and Opus versions) by Anthropic, ChatGPT-5 by OpenAI, Grok by xAI, and Gemini by Google. All interactions were documented and archived in a dedicated Claude project for complete traceability (Project link)."
  },
  {
    "objectID": "llm-reflection.html#ai-statement",
    "href": "llm-reflection.html#ai-statement",
    "title": "LLM Usage and Reflection",
    "section": "",
    "text": "Our group extensively utilized multiple artificial intelligence tools throughout this avalanche prediction neural network project, employing a systematic and transparent approach to AI integration. The tools included Claude (Sonnet and Opus versions) by Anthropic, ChatGPT-5 by OpenAI, Grok by xAI, and Gemini by Google. All interactions were documented and archived in a dedicated Claude project for complete traceability (Project link)."
  },
  {
    "objectID": "llm-reflection.html#phases-of-ai-utilization",
    "href": "llm-reflection.html#phases-of-ai-utilization",
    "title": "LLM Usage and Reflection",
    "section": "Phases of AI Utilization",
    "text": "Phases of AI Utilization\nAI tools supported key stages of our data science workflow:\n\nExploratory Data Analysis (EDA): Assisted in identifying trends and patterns in the Scotland avalanche forecasts dataset.\nModel Development and Preprocessing: Provided guidance on handling missing data imputation, outlier detection/treatment, and class imbalance. Suggested methods included median imputation by geographic area for numerical variables, mode imputation by area for categorical variables, and context-specific outlier thresholds (e.g., capping altitude at Scotlandâ€™s highest peak of 1,345m).\nCode Development: Generated comprehensive R code using keras3 and TensorFlow, based on our EDA findings and requirements. Key prompts covered outlier assessment, missing value strategies, model architecture (including Random Forest feature selection and hyperparameter tuning via grid search), and data splitting (e.g., adjusting from 80/10/10 to 70/15/10 ratios). Also aided debugging, such as transitioning from manual upsampling to ROSE techniques.\nReport Writing and Review: Helped draft analysis sections, interpret evaluation metrics, and perform proofreading, spell-checking, and grammar verification.\n\nWe maintained critical oversight: All AI-generated content was verified against avalanche forecasting literature and Scottish meteorological standards, with code tested for functionality in our dataset context."
  },
  {
    "objectID": "llm-reflection.html#benefits-and-verification",
    "href": "llm-reflection.html#benefits-and-verification",
    "title": "LLM Usage and Reflection",
    "section": "Benefits and Verification",
    "text": "Benefits and Verification\nAI integration offered substantial advantages: - Accelerated timelines and exposure to advanced techniques. - Comprehensive code documentation and creative problem-solving.\nAccuracy was verified through: - Cross-referencing with peer-reviewed research. - Systematic code testing and manual spot-checks. - Comparing outputs across tools for inconsistencies. - Domain-specific evaluation of methodologies."
  },
  {
    "objectID": "llm-reflection.html#critical-reflection",
    "href": "llm-reflection.html#critical-reflection",
    "title": "LLM Usage and Reflection",
    "section": "Critical Reflection",
    "text": "Critical Reflection\nAI tools demonstrated significant strengths but also limitations:\n\nAdvantages: Excelled in generating syntactically correct code and providing creative solutions, enhancing efficiency and innovation.\nLimitations: Occasionally suggested technically sound but contextually unsuitable approaches, lacking nuance in domain-specific factors (e.g., Scottish mountain meteorology). Different tools sometimes gave conflicting advice, requiring synthesis and judgment.\n\nUltimately, AI serves as a powerful assistant but cannot replace human critical thinking, domain expertise, or methodological rigor. This project highlighted the importance of thoughtful, transparent AI use to amplify capabilities while maintaining control."
  }
]