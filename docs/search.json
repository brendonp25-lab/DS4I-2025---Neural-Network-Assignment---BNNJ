[
  {
    "objectID": "paper.html",
    "href": "paper.html",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "Introduction\nBackground\nDataset\nMethodology\nEDA\n\nTarget Variable Distribution\nMissing Data Analysis\nTemporal Analysis\n\nData Processing\n\nOutlier Detection\nFeature Engineering\nImputation for Missing Values\nTarget Encoding\nFeature Selection\n\nImplementation\n\nData Splitting and ROSE Balancing\nNeural Network Architecture\n\nModel Performance Evaluation\n\nOverall Performance\nConfusion Matrix and Class-Level Performance\nConfidence-Based Reliability\nAvalanche-Specific Safety Metrics\n\nFeature Importance Assessment\nConclusion and Recommendations\nAuthor Contributions\nReferences (APA)\n\n\n\nAvalanche forecasting integrates mountain meteorology, snowpack physics, terrain analysis, and risk communication to reduce loss of life and support safer winter travel. In Scotland, the Scottish Avalanche Information Service (SAIS) publishes daily next-day hazard assessments across six high-mountain regions during winter which draws upon field observations, snowpack tests and weather guidance (Scottish Avalanche Information Service [SAIS], n.d.). This report contributes a data-driven complement to that long-running operational effort. Our task is defined as to construct and evaluate a neural network model that predicts the forecasted avalanche hazard (FAH).\nThis research isn’t meant to replace expert judgment. It gives forecasters a second opinion that consistently flags risky combinations of weather, terrain, and snowpack variables. In Scotland’s maritime, wind-dominated winters with frequent storm cycles and rapid thaw freeze shifts this kind of decision support sharpens situational awareness and strengthens risk communication (SAIS, n.d.; EAWS, n.d.).\n\n\n\nScotland’s avalanche forecasts are produced by the Scottish Avalanche Information Service (SAIS). The SAIS conducts daily fieldwork, snow profiles, stability tests and terrain analysis that is blended with meteorological guidance to issue next-day public danger ratings, snowpack summaries and travel advice. This information spans Torridon, Northern Cairngorms, Southern Cairngorms, Creag Meagaidh, Lochaber, and Glencoe. The communication follows the standard EAWS danger scale to keep messages consistent and comparable.\nAvalanches are rapid snow flows that can contain ice, rock, and vegetation. The most dangerous to travellers are slab avalanches, where a cohesive slab slides on a weaker layer once shear strength is exceeded by gravitational and external loading. The triggers for an avalanche may be natural (snowfall, wind loading, warming) or manmade (a skier, climber, or snowmobile). These avalanches most often occur on slopes around 34–45 degrees. In Scotland’s maritime, wind-dominated winters wind slabs are common (Schweizer, Jamieson, & Schneebeli, 2003).\nAvalanche forecasting looks to improving consistency, calibration, and timeliness of hazard assessments which can essentially save lives and reduce societal costs. In Europe, despite substantial growth in backcountry participation, the long-term average annual avalanche fatality count has remained broadly steady at 100 per year across the Alps. This is attributed in part to better education, equipment, and forecasting (Techel et al., 2016). Scotland’s totals are smaller, but fatal and non-fatal involvements recur most winters and SAIS seasonal reports routinely document hundreds of observed avalanches (SAIS, n.d.). The impacts however extend beyond casualty numbers as they tend to disrupt transport, tourism, and emergency services.\n\n\n\nThe dataset is an operational archive produced by the Scottish Avalanche Information Service (SAIS). It spans approximately fifteen winter seasons and reflects real-time fieldwork. Forecasters collect these records in severe weather environments and under time constraints. As a result, the data shows uneven sampling across storm cycles and regions, along with missing entries during periods of limited access.\nThe variables in the dataset include physically informed features from the environment. They are grouped into categories below. A complete list of all variables, including their descriptions, data types, and basic statistics, is provided in the Appendix.\n\n\nSlope angle is the primary release control for slab avalanches, as most events initiate between the mid-30s and mid-40s degrees. Thus, Incline serves as a direct indicator of where failures are most likely. Aspect determines how much wind and sun a slope receives; when analyzed with recent Wind.Dir, it identifies lee (wind-loaded) and windward slopes. Alt specifies the altitude of the observation site in meters above sea level (McClung & Schaerer, 2006; Schweizer, Jamieson, & Schneebeli, 2003).\n\n\n\nNear-surface Air.Temp highlights warm spells that weaken snow bonds. Wind.Dir and Wind.Speed together govern snow transport, building slabs quickly on lee and cross-loaded slopes. Cloud cover influences cooling and heating, driving near-surface faceting or slowing refreezing. Precip.Code indicates the type and intensity of new loading (e.g., snow or showers). Rain.at.900 flags rainfall at 900m altitude, which affects snowmelt. Field Drift observations confirm recent snow blowing. Summit.* variables describe conditions at the summit, where most loading begins (EAWS, n.d.; McClung & Schaerer, 2006; Schweizer et al., 2003).\n\n\n\nTotal.Snow.Depth reflects total depth of snow cover at the observation site, while Foot.Pen/Ski.Pen indicate near-surface strength. Max.Temp.Grad signals the temperature across the snowpack indicating instability. Max.Hardness.Grad captures hardness within the snowpack reflecting the layer differences. Snow.Temp defines the temperature within the snowpack and Wetness defines the degree of snow wetness. Crystals identify type or size of snow crystals observed which influences avalanche risk. Snow.Index provides cues on the stability of the snow. AV.Cat classifies avalanches by type/severity. Insolation measures the impact of solar radiation affecting snow melt. (EAWS, n.d.; Schweizer et al., 2003; McClung & Schaerer, 2006).\nBy relating these predictors to FAH the model can learn recurrent, non-linear patterns. It highlights situations where higher hazard is more likely, so forecasters can focus their checks and make cleaner day-to-day calls (EAWS, n.d.; SAIS, n.d.).\n\n\n\n\nThis research builds a supervised, ordinal-aware classification pipeline to predict next-day Forecast Avalanche Hazard (FAH) from the operational SAIS records. The end-to-end workflow was implemented in R and organized into clearly defined stages—data auditing, preprocessing, feature engineering, imputation, encoding, feature selection, data splitting and class rebalancing, neural-network modeling, and evaluation. Reproducibility is enforced via set.seed(42) and some of the core libraries include tidyverse for data wrangling, caret for preprocessing/splitting, glmnet/randomForest for feature selection signals, ROSE for class balancing, and keras3/tensorflow for model training.\nWe used large language models (LLMs) to accelerate routine coding tasks. Each team member supplied an LLM with a structured brief (data schema, variable descriptions, target definition, leakage constraints, evaluation metrics) to draft boilerplate R code for preprocessing, imputation functions, model scaffolding (keras3), and plotting. To promote diversity of ideas and reduce single-model bias, different teammates intentionally used different LLMs. This use of LLMs sped up drafting, but final code, methodological choices, and validation remained human-curated.\n\n\n\n\n\n\n\n\n\n\n\nBar chart showing the distribution of the FAH target variable\n\n\n\n\nFigure 1: Bar chart of FAH distribution\n\n\n\n\n\n\n\n\n\nPie chart showing the percentage distribution of the FAH target variable\n\n\n\n\nFigure 2: Pie chart of FAH distribution\n\n\n\nFrom Figure 1 and Figure 2, we observe that the FAH target variable exhibits severe class imbalance, with safer classes dominating the distribution: Low (≈32.5%) and Moderate (≈30.7%) together account for ≈63% of observations, while Considerable- is moderately represented (≈23.6%). In contrast, the higher-risk classes—Considerable+ (≈8.8%) and especially High (≈4.4%)—are rare. This skew implies that a model could achieve high overall accuracy by favoring common classes while failing to detect infrequent but critical high-hazard events. To mitigate this, we employ ROSE balancing during training and prioritize macro-averaged metrics alongside high-risk class recall in evaluation.\n\n\n\n\n\n\n\n\n\nGraph showing missing data diagnostics across variables\n\n\n\n\nFigure 3: Missing data analysis graph\n\n\n\nFrom Figure 3, the missing data diagnostics reveal that AV_Cat and Ski_Pen exhibit the highest gaps (≈20%+), prompting their removal from the dataset during preprocessing. Following these, a cluster of snowpack microstructure and condition variables (e.g., Crystals, Wetness, No_Settle) show moderate missingness, alongside certain wind-direction and temperature fields. The target variable FAH has negligible missingness, likely due to operational teams making inferences when weather conditions do not allow for some metrics to be captured.\n\n\n\n\n\n\n\n\n\nGroup of graphs showing temporal coverage and seasonal patterns\n\n\n\n\nFigure 4: Temporal analysis graphs\n\n\n\nFrom Figure 4 that denotes temporal coverage we can see that the archive spans many winters with stable annual volumes after the early years and a strong seasonal concentration in Dec–Mar, tapering in shoulder months and near-zero in summer (as expected). The daily series shows a burst of entries followed by lulls which tell us that data arrives in clusters during winter storm cycles and thin out outside winter. These patterns justify including month/season features and caution against assuming stationarity across years.\n\n\n\n\n\n\nGraph comparing FAH versus OAH pairs\n\n\n\n\nFigure 5: FAH vs OAH comparison graph\n\n\n\nFrom Figure 5, which analyses FAH versus OAH pairs as a verification benchmark for forecast reliability, we observe an overall accuracy of approximately 70–75%. Per-class performance varies notably: accuracy is highest for Low risk (mid-90s%), followed by Moderate (70%), then decreases for Considerable- (60–70%), drops substantially for Considerable+ (35%), and improves slightly for High (~45%). This pattern suggests that forecasters—and by extension, predictive models—struggle most with distinguishing adjacent hazard boundaries. Accordingly, our model evaluation emphasizes ordinal metrics such as adjacent accuracy (±1 level), critical-miss rate (underpredicting high risk), and high-risk sensitivity to ensure practical utility in avalanche forecasting.\nThe EDA completed paints a clear operational picture with our target strongly skewed toward Low/Moderate days, so hence a model judged on plain accuracy could look good while failing on the rare but consequential upper hazards. In the implementation, we therefore look to rebalance the training split with ROSE and commit to macro metrics and high-risk recall at evaluation. The missingness is structured and not entirely random, primarily with the &gt;20% gaps in AV.Cat and Ski.Pen which we drop. The clusters in snowpack detail fields and some wind directions reinforce the choice of Area×Season imputation (fit on train only) and the inclusion of seasonal features. The temporal profile confirms winter-centric usage with stable annual volumes, motivating Month/Season encodings and caution about year-to-year drift. Finally, FAH–OAH verification (~70–75% overall, strongest on Low, weakest in the Considerable+/High tail) mirrors the hardest real-world boundaries, hence we will look to prioritize adjacent accuracy (±1), critical-miss rate, and high-risk sensitivity to ensure the model not only performs well on average but reliably catches dangerous days.\n\n\n\n\nAfter initial data cleaning, we removed non-predictive fields (OAH, Obs) and filtered out the 1% of rows with missing FAH which left us with 10,562 usable records.The FAH values were standardized into five clean categories with the following counts: Low 3,433, Moderate 3,239, Considerable− 2,498, Considerable+ 933, High 459 this was confirming a strong skew toward safer days.\nA missingness audit showed two variables with &gt;20% gaps—AV.Cat (23.4%) and Ski.Pen (22.5%) these we then dropped to avoid heavy, low-confidence imputation. The next tier of missingness is moderate and structured rather than random. Core near-surface weather and geometry variables have very low gaps (≤1–3%). These patterns motivate our Area×Season imputation (fit on the training split only).\n\n\nTo stabilise modelling while preserving the signal, we applied a two-tier outlier process. First, we converted any string “NA”s to true NAs and used a robust IQR filter (k = 3.5) on key continuous variables, while looking to prune only extreme spikes: Alt (2), Wind.Speed (22), Summit.Wind.Speed (81), Total.Snow.Depth (111), Air.Temp (1), Summit.Air.Temp (0), and Foot.Pen (34). Second, we enforced physical plausibility rules and essentially removed Aspect &gt; 360° (8), constrained Cloud to [0,100]% (3), and limited Incline to [0,90]° (5). In total, 267 rows (2.53%) were dropped. This keeps legitimate extremes (e.g., high winds/depths during storms) while eliminating impossible or clearly erroneous readings that would distort scaling, inflate variance, and hinder neural-network optimisation.\nThe boxplots show two kinds of outliers. Some are implausible values with AV.Cat having huge positive/negative magnitudes and &gt;20% missingness. Cloud occasionally exceeds 100% or goes negative. The others may be described as legitimate extremes as Snow.Index has a heavy right tail, Crystals has rare large values amid many zeros, and Rain.at.900 behaves like a binary indicator (0/1), so the “1”s only look like outliers on a numeric boxplot. Latitude spans the expected Scottish band and is not a true outlier.\nGuided by this, we used a two-tier outlier strategy by first applying a physical-plausibility filters to drop AV.Cat, cap Cloud to [0,100], discard Aspect &gt; 360°, Incline &lt;0 or &gt;90°, and remove negative or absurd readings for wind, snow depth, and penetrations. Second, for variables where extremes are meaningful we used robust IQR trimming with a wide cutoff (k≈3–3.5) to prune only extreme spikes while preserving genuine storm extremes. We also recast Rain.at.900 as a binary feature to avoid mislabelling valid “1”s as outliers. This approach reduces measurement/error noise, stabilizes scaling and NN training.\n\n\n\nWe developed a small set of mechanism-aware features to turn raw measurements into signals the model can learn from. A Wind_Chill proxy (Air.Temp − 0.6×Wind.Speed) captures near-surface cooling that weakens bonds under strong winds. A Temp_Gradient (Summit.Air.Temp − Air.Temp) approximates vertical stability and transport potential. Snow_Alt_Interaction (Total.Snow.Depth × Alt/1000) lets snowfall load scale with elevation and the rain–snow line. Because Aspect is circular (0°≈360°), we encoded it as Aspect_North = cos(Aspect) and Aspect_East = sin(Aspect) to avoid artificial discontinuities and to align with wind-loading geometry. Finally, we added Month, Day_of_Year, and Season to reflect the strong winter seasonality seen in the EDA and to let the network learn intra-season cycles (e.g., cold spells vs. thaw pulses). Collectively, these features reduce redundancy, respect data geometry, and embed avalanche mechanics directly into the predictors.\n\n\n\n\n\n\nCorrelation heatmap revealing relationships among variables\n\n\n\n\nFigure 6: Correlation heatmap\n\n\n\nThe correlation heatmap in Figure 6 reveals coherent but mostly moderate correlation clusters among variables. Notably, temperatures (Air.Temp, Summit.Air.Temp) exhibit strong covariation, while Cloud and Insolation show the expected inverse relationship. Wind speeds correlate across levels with some directional noise, and penetration/strength metrics (Foot.Pen, Ski.Pen) associate with Total.Snow.Depth in predictable ways. Meanwhile, Max.Temp.Grad and Max.Hardness.Grad relate to temperature and snow-structure variables through more complex mechanisms, likely tied to metamorphic processes in the snowpack. Overall, this indicates potential multicollinearity, particularly among thermodynamic and wind features, which could destabilize linear models and hinder neural network convergence. To address this, we implemented ensemble feature selection combining LASSO regularization, random forest importance scoring, and correlation-based filtering to minimize redundancy.\nLeveraging these patterns, we engineered targeted features to capture key avalanche mechanics in stable, low-redundancy forms:\n\nWind–cold interaction: a simple wind-chill proxy (Air.Temp − 0.6×Wind.Speed) to reflect near-surface cooling.\nVertical stability: summit–valley temperature gradient (Summit.Air.Temp − Air.Temp) as a rough indicator of atmospheric stratification/transport potential\nSnow–altitude interaction: Total.Snow.Depth × (Alt/1000) to allow depth effects to vary with elevation (rain/snow line).\nCircular aspect encoding: cos(Aspect) and sin(Aspect) to preserve directionality without discontinuity at 360°/0°.\nSeasonality: calendar Month, Day_of_Year, and Season factors to capture intra-winter cycles.\n\n\n\n\nWe address missing data with a context-aware, hierarchical imputation routine that mirrors how avalanche conditions vary across space and season. First, for each Area×Season group we fill numeric gaps with the group median (robust to outliers) and categorical gaps with the group mode, so replacements reflect typical conditions for that region and time of year rather than a blunt global average. Next, any leftovers are handled with global medians/modes as a conservative fallback. We explicitly exclude non-predictive and target fields (Date, OSgrid, Location, FAH) from imputation to avoid leakage into the label. This design preserves regional/seasonal structure noted in the EDA while producing a complete feature matrix for modelling.\n\n\n\nTo prepare the data for a neural network, we first removed non-predictive IDs (Date, OSgrid, Location) and encoded the target, FAH, as an ordinal integer in true risk order Low→High = 0–4. A verification table confirmed a one-to-one mapping (Low=0, Moderate=1, Considerable−=2, Considerable+=3, High=4) with no unmapped values and the encoded class counts [3398, 3167, 2412, 895, 423], matching the observed imbalance.\nFor predictors, we cleaned categorical fields and applied a frequency threshold (≥50) so very rare levels were folded into “Other” to limit sparsity. We then one-hot encoded the remaining categories for Area, Precip.Code, and Season, while adding binary indicator columns and dropping the original fields. This pipeline preserves the ordinal meaning of the hazard label while transforming categorical inputs into a numerically stable representation that dense neural networks can learn from, with reduced risk of overfitting to tiny categories.\n\n\n\nAfter cleaning and encoding, we standardized all numeric predictors and ran an ensemble feature-selection procedure on the 7,530 complete cases to concentrate signal and control dimensionality. Three complementary signals were computed per feature—LASSO coefficients (linear sparsity), Random Forest permutation importance (non-linear/interaction effects), and target correlation—each normalized to 0–100 and combined with weights (RF 40%, LASSO 30%, Correlation 30%). LASSO retained 30 features, Random Forest and correlation evaluated 47 while the weighted scores yielded a final shortlist of 25 predictors. The top-ranked variables are physically coherent with avalanche mechanics are\n\nFoot.Pen (near-surface strength)\nDrift (recent wind transport)\nSummit.Air.Temp and Air.Temp (thermal state)\nTotal.Snow.Depth (load)\nWind.Speed/Summit.Wind.Speed (loading potential)\nMax.Temp.Grad (faceting potential)\nSnow.Temp\nInsolation\nWind_Chill, Snow_Alt_Interaction, and Day_of_Year (engineered terms)\nPrecip.Code\nSeason_Winter\nArea_Lochaber and Area_Torridon\n\n\n\n\n\n\n\nThe cleansed dataset of 7,530 observations was split into training (70%), validation (15%), and test (15%) sets, stratified by hazard level to maintain class proportions. This yielded 5,273 training samples, 1,129 validation samples, and 1,128 test samples from the 7,530 complete cases. The training set reflected the dataset’s imbalance, with Low (class 0) and Moderate (class 1) each &gt;1,700 samples, versus only 145 for High (class 4)—an imbalance ratio of ~12.4:1. Validation and test sets preserved similar distributions, retaining the rarity of high-hazard classes.\nTo mitigate bias toward majority classes, ROSE balancing was applied solely to the training data post-split, keeping validation/test sets natural for unbiased evaluation. Using an iterative one-versus-rest approach (since ROSE is binary-native), synthetic samples were generated for minorities until they reached ~95% of majority size, avoiding perfect balance.\nThe training set grew from 5,273 to 8,641 samples, with ~1,700 per class, reducing the imbalance ratio to 1.05:1 (a 91.5% improvement). This enhanced minority representation for neural network training while ensuring realistic evaluation.\n\n\n\nAfter hyperparameter tuning across three candidate configurations, the optimal network achieved a validation accuracy of 0.6023. The final architecture consisted of three hidden layers (384, 192, 96 units) with progressively increasing dropout (0.25, 0.35, 0.45) and Gaussian noise regularization to control overfitting. The network used the Adam optimizer with a learning rate of 8e-04, a batch size of 48, and trained for 53 epochs.\n\n\n\nLayer\nUnits\nDropout\nNotes\n\n\n\n\nInput\n–\n–\n25 selected features\n\n\nHidden Layer 1\n384\n0.25\nDense + BatchNorm + GaussianNoise\n\n\nHidden Layer 2\n192\n0.35\nDense + BatchNorm + Dropout\n\n\nHidden Layer 3\n96\n0.45\nDense + BatchNorm + Dropout\n\n\nOutput\n5\n–\nSoftmax (multiclass, ordinal)\n\n\n\nTable 4: Final neural network architecture\nThe training and validation curves showed that the model achieved stable convergence, though validation accuracy plateaued around 0.60, reflecting the intrinsic difficulty of predicting the rare high-risk classes.\n\n\n\n\n\n\nThe neural network’s performance was assessed across the training, validation, and test datasets to evaluate both its learning capacity and generalization ability. During training, the model achieved a best validation accuracy of 60.2%, closely matching its final test accuracy of 61.2% (loss = 0.978). This alignment between validation and test performance suggests that the model did not overfit during training and generalized reasonably well to unseen data. By contrast, the naive baseline accuracy, derived from the most frequent class (Moderate, 33.7% of the test set), was substantially lower, meaning the network delivered an 81.6% relative improvement over this trivial predictor.\nThe exploratory data analysis (EDA) helps contextualize this outcome. The FAH distribution was highly imbalanced, with Low and Moderate levels dominating and High being rare. Although the training set was balanced using ROSE, the validation and test sets retained the natural skew, which explains why the model consistently performed better on common classes than on rare ones. Geographical and seasonal patterns also shaped this performance: areas like Lochaber and Torridon contributed disproportionately more samples, while High hazard levels clustered during winter peaks. These structural imbalances likely reinforced the network’s ability to learn Low and Moderate risks while limiting its accuracy on rarer categories.\nBeyond accuracy, complementary metrics provided a broader view of generalization. The macro-averaged scores (precision = 0.527, recall = 0.471, F1 = 0.487) showed that the model was only moderately effective when all classes were weighted equally. However, the weighted averages (precision = 0.598, recall = 0.612, F1 = 0.602) were notably higher, reflecting stronger performance on the dominant classes. Cohen’s Kappa, at 0.449, placed the model in the “moderate agreement” range, confirming that predictions were significantly better than random guessing but not yet highly reliable. EDA findings again provide insight: the removal of several snowpack variables with &gt;20% missingness reduced predictive richness, while the presence of extreme but plausible outliers (e.g., high winds, deep snow) may have complicated learning for rarer hazard levels.\nGiven the ordinal nature of avalanche hazards, the model’s error magnitudes were as critical as accuracy. Predictions deviated by an average of only 0.45 hazard levels (MAE), with relatively low dispersion (RMSE = 0.765). Adjacent accuracy was exceptionally high (94.3% within ±1 level), while extreme errors were nearly absent (99.5% within ±2 levels; 100% within ±3 levels). These results confirm that large misclassifications, such as predicting Low when the true level was High, were virtually eliminated. This aligns with EDA findings showing that extreme meteorological conditions—like heavy snowfall or very high winds—rarely coincided with Low hazard levels, giving the model strong boundaries at the extremes.\nFinally, correlation-based measures demonstrated the network’s ability to preserve ordinal structure. Strong monotonic relationships were observed between predicted and actual hazard levels (Spearman’s ρ = 0.736; Pearson r = 0.720), while Kendall’s Tau (0.669, p &lt; 0.001) and directional accuracy (0.714) indicated consistent ordering across hazard categories. Taken together, these results reveal that although the model achieved only moderate exact-match accuracy, it maintained ordinal consistency, avoided catastrophic misclassifications, and delivered meaningful improvements over baseline predictors.\n\n\n\nThe confusion matrix offered a clear breakdown of how the model performed across individual hazard levels. For the Low hazard class, the network achieved strong results (sensitivity = 0.798, precision = 0.734), reflecting consistent identification of stable snowpack conditions. This strength is consistent with EDA findings, which showed that Low days were associated with distinct signals — shallow snow depth, weak drift, and stable temperature gradients — making them easier for the model to separate. Similarly, the Moderate class reached moderate reliability (sensitivity = 0.597, precision = 0.562), supported by its high prevalence in the dataset and relatively consistent meteorological profiles. Together, these two classes accounted for most correct predictions, reflecting both their dominance in the dataset and their clearer predictor signatures.\nThe Considerable– class performed less consistently (precision = 0.554, recall = 0.541). Misclassifications were concentrated between adjacent levels: 87 cases confused with Moderate and 17 with Considerable+. This behaviour aligns with the transitional nature of predictors highlighted in the EDA, where snow depth, crystal type, and summit air temperature overlapped substantially between Moderate and Considerable– categories.\nPerformance deteriorated for the Considerable+ and High hazard levels, which achieved very low recall (0.205 and 0.212, respectively). High cases were most often misclassified as Considerable– (13) or Considerable+ (11), but crucially, none were mistaken for Low. This indicates that while the model struggled to distinguish among upper hazard levels, it preserved ordinal structure and avoided catastrophic misclassifications. The EDA findings explain this limitation: these rare categories comprised less than 5% of the dataset and were characterized by overlapping meteorological signals such as heavy snowfall, wind drift, and deep weak layers. With limited training samples, the network could not fully disentangle these patterns.\nThe per-class F1-scores reflected this gradient in performance: Low (0.765) and Moderate (0.579) were acceptable, Considerable– was moderate (0.548), while Considerable+ (0.258) and High (0.286) were poor. These values highlight the central trade-off of the model: strong utility in predicting stable and moderately unstable conditions, but weak reliability in capturing rare but operationally critical high-risk categories.\n\n\n\nThe analysis of prediction probabilities revealed that most test predictions were made with low confidence (≤0.6, 59.8%), while only a small share were high-confidence (&gt;0.8, 10.8%). This indicates that the model was generally conservative in assigning strong certainty, reflecting the inherent difficulty of distinguishing avalanche hazard levels under overlapping meteorological conditions.\nAccuracy closely followed confidence level. High-confidence predictions achieved 90.2% accuracy, showing that when the network was certain, it was usually correct. Medium-confidence predictions (71.0%) were moderately reliable, while low-confidence predictions (51.1%) approached random chance. This gradient demonstrates that prediction probabilities serve as a valid proxy for model reliability.\nThese findings are consistent with the EDA results. The overlap of predictor distributions in intermediate hazard levels especially Moderate and Considerable– produced ambiguous cases that drove the majority of low-confidence predictions. By contrast, high-confidence predictions were concentrated in the Low hazard class, where EDA showed distinctive conditions such as shallow snow depth, minimal drift, and stable thermal gradients.\nOperationally, these results highlight the importance of confidence-aware interpretation. High-confidence predictions could be used directly in forecasting workflows, while low-confidence outputs should be flagged for expert review or supplemented by additional modelling. This stratified reliability provides an operational safeguard, ensuring that machine learning support enhances decision-making without introducing undue risk in ambiguous cases.\n\n\n\nThe model’s safety evaluation revealed both conservative tendencies and critical weaknesses. The Critical Miss Rate was 21.6%, meaning over one in five severe avalanche cases (Considerable+ or High) were underestimated as Low or Moderate. This was linked to overlapping predictor patterns between Moderate and higher levels, as identified in the EDA, and the scarcity of severe events (&lt;5% of cases).\nDespite this, the model achieved 74.9% Safety Effectiveness, correctly predicting at or above the true hazard level in most cases. However, the Conservative Bias was slightly negative (–0.114), reflecting a mild overall tendency to underestimate risk. High-risk detection showed mixed results: Sensitivity was 67.9%, indicating some missed severe cases, while Specificity reached 91.8%, showing reliable performance in avoiding false alarms.\n\n\n\n\nThe feature importance analysis revealed that predictors strongly aligned with established avalanche science and EDA findings. Foot Penetration and Drift were the top-ranked features, reflecting their direct links to snowpack weakness and wind-driven slab formation. Key atmospheric drivers — Summit Air Temperature and Total Snow Depth — also ranked highly, confirming their influence on hazard variability observed in the EDA. Crystal Type added further insight into snow microstructure transitions, especially between Moderate and Considerable– categories.\nWind- and temperature-related factors such as Air Temperature, Wind Chill, and Wind Speed consistently scored highly across methods, echoing EDA findings on strong thermal gradients and wind redistribution as critical instability drivers. Seasonal and temporal features — particularly Winter, Day of Year, and Snow–Altitude Interaction — captured the clustering of high hazard levels during winter peaks and at higher elevations. Geographical indicators such as Lochaber and Torridon added spatial context, though with secondary importance.\nIn summary, the most important features reflected a combination of snowpack properties, meteorological drivers, and seasonal patterns, confirming that the model’s predictive behaviour was rooted in meaningful physical processes identified during the exploratory analysis.\n\n\n\n\n\n\nGroup of graphs and diagrams showing feature importance\n\n\n\n\nFigure 7: Feature importance graphs\n\n\n\n\n\n\nThe neural network achieved 61.2% accuracy on the test set, an 81.6% improvement over the baseline. While exact classification was moderate, ordinal metrics showed strong performance, with 94.3% of predictions within ±1 hazard level and a mean absolute error of 0.45 levels. Large misclassifications were rare, and the model preserved the ordered structure of avalanche danger ratings. Performance was strongest for Low and Moderate hazards but weaker for Considerable+ and High, reflecting class imbalance noted in the EDA. The critical miss rate of 21.6% highlights risks of underestimating severe conditions, though the model generally erred conservatively, with 74.9% safety effectiveness. Key predictors included Foot Penetration, Drift, Summit Air Temperature, Total Snow Depth, and Crystal structure, alongside temporal and seasonal variables, confirming both snowpack and climatic influences on avalanche hazard.\nTo improve performance, future work should focus on better representation of high-hazard cases, possibly through expanded datasets or transfer learning. Ensemble methods and uncertainty-based outputs could also increase operational reliability. While not yet suitable as a standalone system, the model shows strong potential as a decision-support tool when combined with expert judgment.\n\n\n\n\nBrendon Pretorius: Formal Analysis, Project Administration, Writing – Review & Editing\nJohan John: Formal Analysis, Writing – Original Draft Preparation\nNabil Patel: Formal Analysis, Methodology, Writing – Original Draft Preparation\nNkateko Mawelele: Formal Analysis, Writing – Original Draft Preparation\n\n\n\n\nBishop, C. M. (2006). Pattern recognition and machine learning. Springer.\nEuropean Avalanche Warning Services. (n.d.). Danger scale and standards. https://www.avalanches.org\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT Press.\nJuvik, E. S. (2023). Toward data-driven decision support for avalanche-exposed roads in Norway. In Proceedings of the International Snow Science Workshop (ISSW 2023). Norwegian Public Roads Administration.\nMcClung, D., & Schaerer, P. (2006). The avalanche handbook (3rd ed.). The Mountaineers Books.\nScottish Avalanche Information Service. (n.d.). About SAIS and daily avalanche reports. https://www.sais.gov.uk\nSchweizer, J., Jamieson, B., & Schneebeli, M. (2003). Snow avalanche formation. Reviews of Geophysics, 41(4), 1–25. https://doi.org/10.1029/2002RG000123\nTechel, F., & Zweifel, B. (2014). Recreational avalanche accidents in Switzerland: Trends and patterns with an emphasis on burial, rescue methods and avalanche danger. Cold Regions Science and Technology, 97, 77–85. https://doi.org/10.1016/j.coldregions.2013.09.006\nTechel, F., Jarry, F., Kronthaler, G., Mitterer, C., Nairz, P., Pavšek, M., Valt, M., & Zweifel, B. (2016). Avalanche fatalities in the European Alps: Long-term trends and perspectives. Cold Regions Science and Technology, 121, 22–31. https://doi.org/10.1016/j.coldregions.2015.11.017"
  },
  {
    "objectID": "paper.html#introduction",
    "href": "paper.html#introduction",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "Avalanche forecasting integrates mountain meteorology, snowpack physics, terrain analysis, and risk communication to reduce loss of life and support safer winter travel. In Scotland, the Scottish Avalanche Information Service (SAIS) publishes daily next-day hazard assessments across six high-mountain regions during winter which draws upon field observations, snowpack tests and weather guidance (Scottish Avalanche Information Service [SAIS], n.d.). This report contributes a data-driven complement to that long-running operational effort. Our task is defined as to construct and evaluate a neural network model that predicts the forecasted avalanche hazard (FAH).\nThis research isn’t meant to replace expert judgment. It gives forecasters a second opinion that consistently flags risky combinations of weather, terrain, and snowpack variables. In Scotland’s maritime, wind-dominated winters with frequent storm cycles and rapid thaw freeze shifts this kind of decision support sharpens situational awareness and strengthens risk communication (SAIS, n.d.; EAWS, n.d.)."
  },
  {
    "objectID": "paper.html#background",
    "href": "paper.html#background",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "Scotland’s avalanche forecasts are produced by the Scottish Avalanche Information Service (SAIS). The SAIS conducts daily fieldwork, snow profiles, stability tests and terrain analysis that is blended with meteorological guidance to issue next-day public danger ratings, snowpack summaries and travel advice. This information spans Torridon, Northern Cairngorms, Southern Cairngorms, Creag Meagaidh, Lochaber, and Glencoe. The communication follows the standard EAWS danger scale to keep messages consistent and comparable.\nAvalanches are rapid snow flows that can contain ice, rock, and vegetation. The most dangerous to travellers are slab avalanches, where a cohesive slab slides on a weaker layer once shear strength is exceeded by gravitational and external loading. The triggers for an avalanche may be natural (snowfall, wind loading, warming) or manmade (a skier, climber, or snowmobile). These avalanches most often occur on slopes around 34–45 degrees. In Scotland’s maritime, wind-dominated winters wind slabs are common (Schweizer, Jamieson, & Schneebeli, 2003).\nAvalanche forecasting looks to improving consistency, calibration, and timeliness of hazard assessments which can essentially save lives and reduce societal costs. In Europe, despite substantial growth in backcountry participation, the long-term average annual avalanche fatality count has remained broadly steady at 100 per year across the Alps. This is attributed in part to better education, equipment, and forecasting (Techel et al., 2016). Scotland’s totals are smaller, but fatal and non-fatal involvements recur most winters and SAIS seasonal reports routinely document hundreds of observed avalanches (SAIS, n.d.). The impacts however extend beyond casualty numbers as they tend to disrupt transport, tourism, and emergency services."
  },
  {
    "objectID": "paper.html#dataset",
    "href": "paper.html#dataset",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "The dataset is an operational archive produced by the Scottish Avalanche Information Service (SAIS). It spans approximately fifteen winter seasons and reflects real-time fieldwork. Forecasters collect these records in severe weather environments and under time constraints. As a result, the data shows uneven sampling across storm cycles and regions, along with missing entries during periods of limited access.\nThe variables in the dataset include physically informed features from the environment. They are grouped into categories below. A complete list of all variables, including their descriptions, data types, and basic statistics, is provided in the Appendix.\n\n\nSlope angle is the primary release control for slab avalanches, as most events initiate between the mid-30s and mid-40s degrees. Thus, Incline serves as a direct indicator of where failures are most likely. Aspect determines how much wind and sun a slope receives; when analyzed with recent Wind.Dir, it identifies lee (wind-loaded) and windward slopes. Alt specifies the altitude of the observation site in meters above sea level (McClung & Schaerer, 2006; Schweizer, Jamieson, & Schneebeli, 2003).\n\n\n\nNear-surface Air.Temp highlights warm spells that weaken snow bonds. Wind.Dir and Wind.Speed together govern snow transport, building slabs quickly on lee and cross-loaded slopes. Cloud cover influences cooling and heating, driving near-surface faceting or slowing refreezing. Precip.Code indicates the type and intensity of new loading (e.g., snow or showers). Rain.at.900 flags rainfall at 900m altitude, which affects snowmelt. Field Drift observations confirm recent snow blowing. Summit.* variables describe conditions at the summit, where most loading begins (EAWS, n.d.; McClung & Schaerer, 2006; Schweizer et al., 2003).\n\n\n\nTotal.Snow.Depth reflects total depth of snow cover at the observation site, while Foot.Pen/Ski.Pen indicate near-surface strength. Max.Temp.Grad signals the temperature across the snowpack indicating instability. Max.Hardness.Grad captures hardness within the snowpack reflecting the layer differences. Snow.Temp defines the temperature within the snowpack and Wetness defines the degree of snow wetness. Crystals identify type or size of snow crystals observed which influences avalanche risk. Snow.Index provides cues on the stability of the snow. AV.Cat classifies avalanches by type/severity. Insolation measures the impact of solar radiation affecting snow melt. (EAWS, n.d.; Schweizer et al., 2003; McClung & Schaerer, 2006).\nBy relating these predictors to FAH the model can learn recurrent, non-linear patterns. It highlights situations where higher hazard is more likely, so forecasters can focus their checks and make cleaner day-to-day calls (EAWS, n.d.; SAIS, n.d.)."
  },
  {
    "objectID": "paper.html#methodology",
    "href": "paper.html#methodology",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "This research builds a supervised, ordinal-aware classification pipeline to predict next-day Forecast Avalanche Hazard (FAH) from the operational SAIS records. The end-to-end workflow was implemented in R and organized into clearly defined stages—data auditing, preprocessing, feature engineering, imputation, encoding, feature selection, data splitting and class rebalancing, neural-network modeling, and evaluation. Reproducibility is enforced via set.seed(42) and some of the core libraries include tidyverse for data wrangling, caret for preprocessing/splitting, glmnet/randomForest for feature selection signals, ROSE for class balancing, and keras3/tensorflow for model training.\nWe used large language models (LLMs) to accelerate routine coding tasks. Each team member supplied an LLM with a structured brief (data schema, variable descriptions, target definition, leakage constraints, evaluation metrics) to draft boilerplate R code for preprocessing, imputation functions, model scaffolding (keras3), and plotting. To promote diversity of ideas and reduce single-model bias, different teammates intentionally used different LLMs. This use of LLMs sped up drafting, but final code, methodological choices, and validation remained human-curated."
  },
  {
    "objectID": "paper.html#eda",
    "href": "paper.html#eda",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "Bar chart showing the distribution of the FAH target variable\n\n\n\n\nFigure 1: Bar chart of FAH distribution\n\n\n\n\n\n\n\n\n\nPie chart showing the percentage distribution of the FAH target variable\n\n\n\n\nFigure 2: Pie chart of FAH distribution\n\n\n\nFrom Figure 1 and Figure 2, we observe that the FAH target variable exhibits severe class imbalance, with safer classes dominating the distribution: Low (≈32.5%) and Moderate (≈30.7%) together account for ≈63% of observations, while Considerable- is moderately represented (≈23.6%). In contrast, the higher-risk classes—Considerable+ (≈8.8%) and especially High (≈4.4%)—are rare. This skew implies that a model could achieve high overall accuracy by favoring common classes while failing to detect infrequent but critical high-hazard events. To mitigate this, we employ ROSE balancing during training and prioritize macro-averaged metrics alongside high-risk class recall in evaluation.\n\n\n\n\n\n\n\n\n\nGraph showing missing data diagnostics across variables\n\n\n\n\nFigure 3: Missing data analysis graph\n\n\n\nFrom Figure 3, the missing data diagnostics reveal that AV_Cat and Ski_Pen exhibit the highest gaps (≈20%+), prompting their removal from the dataset during preprocessing. Following these, a cluster of snowpack microstructure and condition variables (e.g., Crystals, Wetness, No_Settle) show moderate missingness, alongside certain wind-direction and temperature fields. The target variable FAH has negligible missingness, likely due to operational teams making inferences when weather conditions do not allow for some metrics to be captured.\n\n\n\n\n\n\n\n\n\nGroup of graphs showing temporal coverage and seasonal patterns\n\n\n\n\nFigure 4: Temporal analysis graphs\n\n\n\nFrom Figure 4 that denotes temporal coverage we can see that the archive spans many winters with stable annual volumes after the early years and a strong seasonal concentration in Dec–Mar, tapering in shoulder months and near-zero in summer (as expected). The daily series shows a burst of entries followed by lulls which tell us that data arrives in clusters during winter storm cycles and thin out outside winter. These patterns justify including month/season features and caution against assuming stationarity across years.\n\n\n\n\n\n\nGraph comparing FAH versus OAH pairs\n\n\n\n\nFigure 5: FAH vs OAH comparison graph\n\n\n\nFrom Figure 5, which analyses FAH versus OAH pairs as a verification benchmark for forecast reliability, we observe an overall accuracy of approximately 70–75%. Per-class performance varies notably: accuracy is highest for Low risk (mid-90s%), followed by Moderate (70%), then decreases for Considerable- (60–70%), drops substantially for Considerable+ (35%), and improves slightly for High (~45%). This pattern suggests that forecasters—and by extension, predictive models—struggle most with distinguishing adjacent hazard boundaries. Accordingly, our model evaluation emphasizes ordinal metrics such as adjacent accuracy (±1 level), critical-miss rate (underpredicting high risk), and high-risk sensitivity to ensure practical utility in avalanche forecasting.\nThe EDA completed paints a clear operational picture with our target strongly skewed toward Low/Moderate days, so hence a model judged on plain accuracy could look good while failing on the rare but consequential upper hazards. In the implementation, we therefore look to rebalance the training split with ROSE and commit to macro metrics and high-risk recall at evaluation. The missingness is structured and not entirely random, primarily with the &gt;20% gaps in AV.Cat and Ski.Pen which we drop. The clusters in snowpack detail fields and some wind directions reinforce the choice of Area×Season imputation (fit on train only) and the inclusion of seasonal features. The temporal profile confirms winter-centric usage with stable annual volumes, motivating Month/Season encodings and caution about year-to-year drift. Finally, FAH–OAH verification (~70–75% overall, strongest on Low, weakest in the Considerable+/High tail) mirrors the hardest real-world boundaries, hence we will look to prioritize adjacent accuracy (±1), critical-miss rate, and high-risk sensitivity to ensure the model not only performs well on average but reliably catches dangerous days."
  },
  {
    "objectID": "paper.html#data-processing",
    "href": "paper.html#data-processing",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "After initial data cleaning, we removed non-predictive fields (OAH, Obs) and filtered out the 1% of rows with missing FAH which left us with 10,562 usable records.The FAH values were standardized into five clean categories with the following counts: Low 3,433, Moderate 3,239, Considerable− 2,498, Considerable+ 933, High 459 this was confirming a strong skew toward safer days.\nA missingness audit showed two variables with &gt;20% gaps—AV.Cat (23.4%) and Ski.Pen (22.5%) these we then dropped to avoid heavy, low-confidence imputation. The next tier of missingness is moderate and structured rather than random. Core near-surface weather and geometry variables have very low gaps (≤1–3%). These patterns motivate our Area×Season imputation (fit on the training split only).\n\n\nTo stabilise modelling while preserving the signal, we applied a two-tier outlier process. First, we converted any string “NA”s to true NAs and used a robust IQR filter (k = 3.5) on key continuous variables, while looking to prune only extreme spikes: Alt (2), Wind.Speed (22), Summit.Wind.Speed (81), Total.Snow.Depth (111), Air.Temp (1), Summit.Air.Temp (0), and Foot.Pen (34). Second, we enforced physical plausibility rules and essentially removed Aspect &gt; 360° (8), constrained Cloud to [0,100]% (3), and limited Incline to [0,90]° (5). In total, 267 rows (2.53%) were dropped. This keeps legitimate extremes (e.g., high winds/depths during storms) while eliminating impossible or clearly erroneous readings that would distort scaling, inflate variance, and hinder neural-network optimisation.\nThe boxplots show two kinds of outliers. Some are implausible values with AV.Cat having huge positive/negative magnitudes and &gt;20% missingness. Cloud occasionally exceeds 100% or goes negative. The others may be described as legitimate extremes as Snow.Index has a heavy right tail, Crystals has rare large values amid many zeros, and Rain.at.900 behaves like a binary indicator (0/1), so the “1”s only look like outliers on a numeric boxplot. Latitude spans the expected Scottish band and is not a true outlier.\nGuided by this, we used a two-tier outlier strategy by first applying a physical-plausibility filters to drop AV.Cat, cap Cloud to [0,100], discard Aspect &gt; 360°, Incline &lt;0 or &gt;90°, and remove negative or absurd readings for wind, snow depth, and penetrations. Second, for variables where extremes are meaningful we used robust IQR trimming with a wide cutoff (k≈3–3.5) to prune only extreme spikes while preserving genuine storm extremes. We also recast Rain.at.900 as a binary feature to avoid mislabelling valid “1”s as outliers. This approach reduces measurement/error noise, stabilizes scaling and NN training.\n\n\n\nWe developed a small set of mechanism-aware features to turn raw measurements into signals the model can learn from. A Wind_Chill proxy (Air.Temp − 0.6×Wind.Speed) captures near-surface cooling that weakens bonds under strong winds. A Temp_Gradient (Summit.Air.Temp − Air.Temp) approximates vertical stability and transport potential. Snow_Alt_Interaction (Total.Snow.Depth × Alt/1000) lets snowfall load scale with elevation and the rain–snow line. Because Aspect is circular (0°≈360°), we encoded it as Aspect_North = cos(Aspect) and Aspect_East = sin(Aspect) to avoid artificial discontinuities and to align with wind-loading geometry. Finally, we added Month, Day_of_Year, and Season to reflect the strong winter seasonality seen in the EDA and to let the network learn intra-season cycles (e.g., cold spells vs. thaw pulses). Collectively, these features reduce redundancy, respect data geometry, and embed avalanche mechanics directly into the predictors.\n\n\n\n\n\n\nCorrelation heatmap revealing relationships among variables\n\n\n\n\nFigure 6: Correlation heatmap\n\n\n\nThe correlation heatmap in Figure 6 reveals coherent but mostly moderate correlation clusters among variables. Notably, temperatures (Air.Temp, Summit.Air.Temp) exhibit strong covariation, while Cloud and Insolation show the expected inverse relationship. Wind speeds correlate across levels with some directional noise, and penetration/strength metrics (Foot.Pen, Ski.Pen) associate with Total.Snow.Depth in predictable ways. Meanwhile, Max.Temp.Grad and Max.Hardness.Grad relate to temperature and snow-structure variables through more complex mechanisms, likely tied to metamorphic processes in the snowpack. Overall, this indicates potential multicollinearity, particularly among thermodynamic and wind features, which could destabilize linear models and hinder neural network convergence. To address this, we implemented ensemble feature selection combining LASSO regularization, random forest importance scoring, and correlation-based filtering to minimize redundancy.\nLeveraging these patterns, we engineered targeted features to capture key avalanche mechanics in stable, low-redundancy forms:\n\nWind–cold interaction: a simple wind-chill proxy (Air.Temp − 0.6×Wind.Speed) to reflect near-surface cooling.\nVertical stability: summit–valley temperature gradient (Summit.Air.Temp − Air.Temp) as a rough indicator of atmospheric stratification/transport potential\nSnow–altitude interaction: Total.Snow.Depth × (Alt/1000) to allow depth effects to vary with elevation (rain/snow line).\nCircular aspect encoding: cos(Aspect) and sin(Aspect) to preserve directionality without discontinuity at 360°/0°.\nSeasonality: calendar Month, Day_of_Year, and Season factors to capture intra-winter cycles.\n\n\n\n\nWe address missing data with a context-aware, hierarchical imputation routine that mirrors how avalanche conditions vary across space and season. First, for each Area×Season group we fill numeric gaps with the group median (robust to outliers) and categorical gaps with the group mode, so replacements reflect typical conditions for that region and time of year rather than a blunt global average. Next, any leftovers are handled with global medians/modes as a conservative fallback. We explicitly exclude non-predictive and target fields (Date, OSgrid, Location, FAH) from imputation to avoid leakage into the label. This design preserves regional/seasonal structure noted in the EDA while producing a complete feature matrix for modelling.\n\n\n\nTo prepare the data for a neural network, we first removed non-predictive IDs (Date, OSgrid, Location) and encoded the target, FAH, as an ordinal integer in true risk order Low→High = 0–4. A verification table confirmed a one-to-one mapping (Low=0, Moderate=1, Considerable−=2, Considerable+=3, High=4) with no unmapped values and the encoded class counts [3398, 3167, 2412, 895, 423], matching the observed imbalance.\nFor predictors, we cleaned categorical fields and applied a frequency threshold (≥50) so very rare levels were folded into “Other” to limit sparsity. We then one-hot encoded the remaining categories for Area, Precip.Code, and Season, while adding binary indicator columns and dropping the original fields. This pipeline preserves the ordinal meaning of the hazard label while transforming categorical inputs into a numerically stable representation that dense neural networks can learn from, with reduced risk of overfitting to tiny categories.\n\n\n\nAfter cleaning and encoding, we standardized all numeric predictors and ran an ensemble feature-selection procedure on the 7,530 complete cases to concentrate signal and control dimensionality. Three complementary signals were computed per feature—LASSO coefficients (linear sparsity), Random Forest permutation importance (non-linear/interaction effects), and target correlation—each normalized to 0–100 and combined with weights (RF 40%, LASSO 30%, Correlation 30%). LASSO retained 30 features, Random Forest and correlation evaluated 47 while the weighted scores yielded a final shortlist of 25 predictors. The top-ranked variables are physically coherent with avalanche mechanics are\n\nFoot.Pen (near-surface strength)\nDrift (recent wind transport)\nSummit.Air.Temp and Air.Temp (thermal state)\nTotal.Snow.Depth (load)\nWind.Speed/Summit.Wind.Speed (loading potential)\nMax.Temp.Grad (faceting potential)\nSnow.Temp\nInsolation\nWind_Chill, Snow_Alt_Interaction, and Day_of_Year (engineered terms)\nPrecip.Code\nSeason_Winter\nArea_Lochaber and Area_Torridon"
  },
  {
    "objectID": "paper.html#implementation",
    "href": "paper.html#implementation",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "The cleansed dataset of 7,530 observations was split into training (70%), validation (15%), and test (15%) sets, stratified by hazard level to maintain class proportions. This yielded 5,273 training samples, 1,129 validation samples, and 1,128 test samples from the 7,530 complete cases. The training set reflected the dataset’s imbalance, with Low (class 0) and Moderate (class 1) each &gt;1,700 samples, versus only 145 for High (class 4)—an imbalance ratio of ~12.4:1. Validation and test sets preserved similar distributions, retaining the rarity of high-hazard classes.\nTo mitigate bias toward majority classes, ROSE balancing was applied solely to the training data post-split, keeping validation/test sets natural for unbiased evaluation. Using an iterative one-versus-rest approach (since ROSE is binary-native), synthetic samples were generated for minorities until they reached ~95% of majority size, avoiding perfect balance.\nThe training set grew from 5,273 to 8,641 samples, with ~1,700 per class, reducing the imbalance ratio to 1.05:1 (a 91.5% improvement). This enhanced minority representation for neural network training while ensuring realistic evaluation.\n\n\n\nAfter hyperparameter tuning across three candidate configurations, the optimal network achieved a validation accuracy of 0.6023. The final architecture consisted of three hidden layers (384, 192, 96 units) with progressively increasing dropout (0.25, 0.35, 0.45) and Gaussian noise regularization to control overfitting. The network used the Adam optimizer with a learning rate of 8e-04, a batch size of 48, and trained for 53 epochs.\n\n\n\nLayer\nUnits\nDropout\nNotes\n\n\n\n\nInput\n–\n–\n25 selected features\n\n\nHidden Layer 1\n384\n0.25\nDense + BatchNorm + GaussianNoise\n\n\nHidden Layer 2\n192\n0.35\nDense + BatchNorm + Dropout\n\n\nHidden Layer 3\n96\n0.45\nDense + BatchNorm + Dropout\n\n\nOutput\n5\n–\nSoftmax (multiclass, ordinal)\n\n\n\nTable 4: Final neural network architecture\nThe training and validation curves showed that the model achieved stable convergence, though validation accuracy plateaued around 0.60, reflecting the intrinsic difficulty of predicting the rare high-risk classes."
  },
  {
    "objectID": "paper.html#model-performance-evaluation",
    "href": "paper.html#model-performance-evaluation",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "The neural network’s performance was assessed across the training, validation, and test datasets to evaluate both its learning capacity and generalization ability. During training, the model achieved a best validation accuracy of 60.2%, closely matching its final test accuracy of 61.2% (loss = 0.978). This alignment between validation and test performance suggests that the model did not overfit during training and generalized reasonably well to unseen data. By contrast, the naive baseline accuracy, derived from the most frequent class (Moderate, 33.7% of the test set), was substantially lower, meaning the network delivered an 81.6% relative improvement over this trivial predictor.\nThe exploratory data analysis (EDA) helps contextualize this outcome. The FAH distribution was highly imbalanced, with Low and Moderate levels dominating and High being rare. Although the training set was balanced using ROSE, the validation and test sets retained the natural skew, which explains why the model consistently performed better on common classes than on rare ones. Geographical and seasonal patterns also shaped this performance: areas like Lochaber and Torridon contributed disproportionately more samples, while High hazard levels clustered during winter peaks. These structural imbalances likely reinforced the network’s ability to learn Low and Moderate risks while limiting its accuracy on rarer categories.\nBeyond accuracy, complementary metrics provided a broader view of generalization. The macro-averaged scores (precision = 0.527, recall = 0.471, F1 = 0.487) showed that the model was only moderately effective when all classes were weighted equally. However, the weighted averages (precision = 0.598, recall = 0.612, F1 = 0.602) were notably higher, reflecting stronger performance on the dominant classes. Cohen’s Kappa, at 0.449, placed the model in the “moderate agreement” range, confirming that predictions were significantly better than random guessing but not yet highly reliable. EDA findings again provide insight: the removal of several snowpack variables with &gt;20% missingness reduced predictive richness, while the presence of extreme but plausible outliers (e.g., high winds, deep snow) may have complicated learning for rarer hazard levels.\nGiven the ordinal nature of avalanche hazards, the model’s error magnitudes were as critical as accuracy. Predictions deviated by an average of only 0.45 hazard levels (MAE), with relatively low dispersion (RMSE = 0.765). Adjacent accuracy was exceptionally high (94.3% within ±1 level), while extreme errors were nearly absent (99.5% within ±2 levels; 100% within ±3 levels). These results confirm that large misclassifications, such as predicting Low when the true level was High, were virtually eliminated. This aligns with EDA findings showing that extreme meteorological conditions—like heavy snowfall or very high winds—rarely coincided with Low hazard levels, giving the model strong boundaries at the extremes.\nFinally, correlation-based measures demonstrated the network’s ability to preserve ordinal structure. Strong monotonic relationships were observed between predicted and actual hazard levels (Spearman’s ρ = 0.736; Pearson r = 0.720), while Kendall’s Tau (0.669, p &lt; 0.001) and directional accuracy (0.714) indicated consistent ordering across hazard categories. Taken together, these results reveal that although the model achieved only moderate exact-match accuracy, it maintained ordinal consistency, avoided catastrophic misclassifications, and delivered meaningful improvements over baseline predictors.\n\n\n\nThe confusion matrix offered a clear breakdown of how the model performed across individual hazard levels. For the Low hazard class, the network achieved strong results (sensitivity = 0.798, precision = 0.734), reflecting consistent identification of stable snowpack conditions. This strength is consistent with EDA findings, which showed that Low days were associated with distinct signals — shallow snow depth, weak drift, and stable temperature gradients — making them easier for the model to separate. Similarly, the Moderate class reached moderate reliability (sensitivity = 0.597, precision = 0.562), supported by its high prevalence in the dataset and relatively consistent meteorological profiles. Together, these two classes accounted for most correct predictions, reflecting both their dominance in the dataset and their clearer predictor signatures.\nThe Considerable– class performed less consistently (precision = 0.554, recall = 0.541). Misclassifications were concentrated between adjacent levels: 87 cases confused with Moderate and 17 with Considerable+. This behaviour aligns with the transitional nature of predictors highlighted in the EDA, where snow depth, crystal type, and summit air temperature overlapped substantially between Moderate and Considerable– categories.\nPerformance deteriorated for the Considerable+ and High hazard levels, which achieved very low recall (0.205 and 0.212, respectively). High cases were most often misclassified as Considerable– (13) or Considerable+ (11), but crucially, none were mistaken for Low. This indicates that while the model struggled to distinguish among upper hazard levels, it preserved ordinal structure and avoided catastrophic misclassifications. The EDA findings explain this limitation: these rare categories comprised less than 5% of the dataset and were characterized by overlapping meteorological signals such as heavy snowfall, wind drift, and deep weak layers. With limited training samples, the network could not fully disentangle these patterns.\nThe per-class F1-scores reflected this gradient in performance: Low (0.765) and Moderate (0.579) were acceptable, Considerable– was moderate (0.548), while Considerable+ (0.258) and High (0.286) were poor. These values highlight the central trade-off of the model: strong utility in predicting stable and moderately unstable conditions, but weak reliability in capturing rare but operationally critical high-risk categories.\n\n\n\nThe analysis of prediction probabilities revealed that most test predictions were made with low confidence (≤0.6, 59.8%), while only a small share were high-confidence (&gt;0.8, 10.8%). This indicates that the model was generally conservative in assigning strong certainty, reflecting the inherent difficulty of distinguishing avalanche hazard levels under overlapping meteorological conditions.\nAccuracy closely followed confidence level. High-confidence predictions achieved 90.2% accuracy, showing that when the network was certain, it was usually correct. Medium-confidence predictions (71.0%) were moderately reliable, while low-confidence predictions (51.1%) approached random chance. This gradient demonstrates that prediction probabilities serve as a valid proxy for model reliability.\nThese findings are consistent with the EDA results. The overlap of predictor distributions in intermediate hazard levels especially Moderate and Considerable– produced ambiguous cases that drove the majority of low-confidence predictions. By contrast, high-confidence predictions were concentrated in the Low hazard class, where EDA showed distinctive conditions such as shallow snow depth, minimal drift, and stable thermal gradients.\nOperationally, these results highlight the importance of confidence-aware interpretation. High-confidence predictions could be used directly in forecasting workflows, while low-confidence outputs should be flagged for expert review or supplemented by additional modelling. This stratified reliability provides an operational safeguard, ensuring that machine learning support enhances decision-making without introducing undue risk in ambiguous cases.\n\n\n\nThe model’s safety evaluation revealed both conservative tendencies and critical weaknesses. The Critical Miss Rate was 21.6%, meaning over one in five severe avalanche cases (Considerable+ or High) were underestimated as Low or Moderate. This was linked to overlapping predictor patterns between Moderate and higher levels, as identified in the EDA, and the scarcity of severe events (&lt;5% of cases).\nDespite this, the model achieved 74.9% Safety Effectiveness, correctly predicting at or above the true hazard level in most cases. However, the Conservative Bias was slightly negative (–0.114), reflecting a mild overall tendency to underestimate risk. High-risk detection showed mixed results: Sensitivity was 67.9%, indicating some missed severe cases, while Specificity reached 91.8%, showing reliable performance in avoiding false alarms."
  },
  {
    "objectID": "paper.html#feature-importance-assessment",
    "href": "paper.html#feature-importance-assessment",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "The feature importance analysis revealed that predictors strongly aligned with established avalanche science and EDA findings. Foot Penetration and Drift were the top-ranked features, reflecting their direct links to snowpack weakness and wind-driven slab formation. Key atmospheric drivers — Summit Air Temperature and Total Snow Depth — also ranked highly, confirming their influence on hazard variability observed in the EDA. Crystal Type added further insight into snow microstructure transitions, especially between Moderate and Considerable– categories.\nWind- and temperature-related factors such as Air Temperature, Wind Chill, and Wind Speed consistently scored highly across methods, echoing EDA findings on strong thermal gradients and wind redistribution as critical instability drivers. Seasonal and temporal features — particularly Winter, Day of Year, and Snow–Altitude Interaction — captured the clustering of high hazard levels during winter peaks and at higher elevations. Geographical indicators such as Lochaber and Torridon added spatial context, though with secondary importance.\nIn summary, the most important features reflected a combination of snowpack properties, meteorological drivers, and seasonal patterns, confirming that the model’s predictive behaviour was rooted in meaningful physical processes identified during the exploratory analysis.\n\n\n\n\n\n\nGroup of graphs and diagrams showing feature importance\n\n\n\n\nFigure 7: Feature importance graphs"
  },
  {
    "objectID": "paper.html#conclusion-and-recommendations",
    "href": "paper.html#conclusion-and-recommendations",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "The neural network achieved 61.2% accuracy on the test set, an 81.6% improvement over the baseline. While exact classification was moderate, ordinal metrics showed strong performance, with 94.3% of predictions within ±1 hazard level and a mean absolute error of 0.45 levels. Large misclassifications were rare, and the model preserved the ordered structure of avalanche danger ratings. Performance was strongest for Low and Moderate hazards but weaker for Considerable+ and High, reflecting class imbalance noted in the EDA. The critical miss rate of 21.6% highlights risks of underestimating severe conditions, though the model generally erred conservatively, with 74.9% safety effectiveness. Key predictors included Foot Penetration, Drift, Summit Air Temperature, Total Snow Depth, and Crystal structure, alongside temporal and seasonal variables, confirming both snowpack and climatic influences on avalanche hazard.\nTo improve performance, future work should focus on better representation of high-hazard cases, possibly through expanded datasets or transfer learning. Ensemble methods and uncertainty-based outputs could also increase operational reliability. While not yet suitable as a standalone system, the model shows strong potential as a decision-support tool when combined with expert judgment."
  },
  {
    "objectID": "paper.html#author-contributions",
    "href": "paper.html#author-contributions",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "Brendon Pretorius: Formal Analysis, Project Administration, Writing – Review & Editing\nJohan John: Formal Analysis, Writing – Original Draft Preparation\nNabil Patel: Formal Analysis, Methodology, Writing – Original Draft Preparation\nNkateko Mawelele: Formal Analysis, Writing – Original Draft Preparation"
  },
  {
    "objectID": "paper.html#references-apa",
    "href": "paper.html#references-apa",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "Bishop, C. M. (2006). Pattern recognition and machine learning. Springer.\nEuropean Avalanche Warning Services. (n.d.). Danger scale and standards. https://www.avalanches.org\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT Press.\nJuvik, E. S. (2023). Toward data-driven decision support for avalanche-exposed roads in Norway. In Proceedings of the International Snow Science Workshop (ISSW 2023). Norwegian Public Roads Administration.\nMcClung, D., & Schaerer, P. (2006). The avalanche handbook (3rd ed.). The Mountaineers Books.\nScottish Avalanche Information Service. (n.d.). About SAIS and daily avalanche reports. https://www.sais.gov.uk\nSchweizer, J., Jamieson, B., & Schneebeli, M. (2003). Snow avalanche formation. Reviews of Geophysics, 41(4), 1–25. https://doi.org/10.1029/2002RG000123\nTechel, F., & Zweifel, B. (2014). Recreational avalanche accidents in Switzerland: Trends and patterns with an emphasis on burial, rescue methods and avalanche danger. Cold Regions Science and Technology, 97, 77–85. https://doi.org/10.1016/j.coldregions.2013.09.006\nTechel, F., Jarry, F., Kronthaler, G., Mitterer, C., Nairz, P., Pavšek, M., Valt, M., & Zweifel, B. (2016). Avalanche fatalities in the European Alps: Long-term trends and perspectives. Cold Regions Science and Technology, 121, 22–31. https://doi.org/10.1016/j.coldregions.2015.11.017"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA5073Z Assignment 1: Avalanche Hazard Prediction",
    "section": "",
    "text": "Welcome to our Avalanche Hazard Prediction project.\n- Scientific Paper\n- LLM Reflection\n- Appendix\n Source: wallpapers.com"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "Appendix",
    "section": "",
    "text": "Data\nThe following table provides descriptions, datatypes, and basic distributional analysis for the dataset variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nData Type\nExample\nDefinition\nNA’s/Blanks\nMissing Percentage (%)\nMin\n1st Qu\nMedian\nMean\n3rd Qu\nMax\n\n\n\n\nDate\ndate\n17/12/2009 12:30\nThe date and time when the observation or forecast was recorded.\n0\n0\n-\n-\n-\n-\n-\n-\n\n\nArea\nchr\nCreag Meagaidh\nThe specific mountain region or forecast area in Scotland (e.g., Creag Meagaidh, Torridon).\n0\n0\n-\n-\n-\n-\n-\n-\n\n\nlongitude\nnum\n-0.392\nThe longitude coordinate of the observation location in decimal degrees.\n0\n0\n-1.2021\n-0.5424\n-0.4315\n-0.3984\n-0.2705\n0.5701\n\n\nlatitude\nnum\n2.22\nThe latitude coordinate of the observation location in decimal degrees.\n0\n0\n1.361\n1.982\n2.198\n2.298\n2.711\n3.08\n\n\nAlt\nint\n800\nAltitude of the observation site in meters above sea level.\n6\n0.05622716\n-1\n800\n910\n934\n1030\n244859\n\n\nAspect\nint\n160\nThe compass direction (in degrees) that the slope faces, relevant to avalanche risk.\n355\n3.3267735\n-1\n50\n90\n153.2\n225\n163770\n\n\nIncline\nint\n28\nThe slope angle (in degrees) where the observation was taken, critical for avalanche potential.\n36\n0.33736295\n-1\n22\n28\n26.76\n32\n1020\n\n\nObs\nchr\nWS\nObservation type or condition code (e.g., WS for Wet Snow, TR for Tracks), indicating snow or terrain state.\n21\n0.197795988\n-\n-\n-\n-\n-\n-\n\n\nFAH\nchr\nModerate\nForecast Avalanche Hazard, the predicted avalanche danger level for the next 24 hours.\n109\n1.026655364\n-\n-\n-\n-\n-\n-\n\n\nOAH\nchr\nModerate\nObserved Avalanche Hazard, the assessed avalanche danger based on current field observations.\n453\n4.266742018\n-\n-\n-\n-\n-\n-\n\n\nAir.Temp\nnum\n-3.2\nAir temperature (in °C) at the observation site, influencing snow stability.\n34\n0.31862056\n-10.8\n-2.1\n-0.2\n0.06021\n2.1\n17\n\n\nWind.Dir\nnum\n45\nWind direction (in degrees) affecting snow distribution and drift formation.\n158\n1.48064849\n-2.6\n150\n220\n202.1\n270\n905\n\n\nWind.Speed\nnum\n10\nWind speed (in km/h or mph), impacting snow transport and avalanche risk.\n53\n0.49667323\n-2\n8\n15\n16.34\n22\n290\n\n\nCloud\nint\n90\nCloud cover percentage, affecting temperature and precipitation patterns.\n29\n0.2717646\n-1\n70\n100\n80.21\n100\n199\n\n\nPrecip.Code\nchr\n2 - Trace\nPrecipitation code indicating type and intensity (e.g., snow, rain, trace).\n583\n5.491193369\n-\n-\n-\n-\n-\n-\n\n\nDrift\nint\n1\nIndicator of snow drifting (1 = present, 0 = absent), affecting stability.\n0\n0\n-\n-\n-\n-\n-\n-\n\n\nTotal.Snow.Depth\nint\n45\nTotal depth of snow cover (in cm) at the observation site.\n163\n1.52750445\n-1\n45\n70\n95.75\n118\n3000\n\n\nFoot.Pen\nnum\n0\nFoot penetration depth (in cm), indicating snowpack consistency.\n42\n0.3935901\n-1\n5\n10\n13.96\n20\n300\n\n\nSki.Pen\nint\nNA\nSki penetration depth (in cm), showing snowpack support for skiing.\n2404\n22.52834786\n-1\n0\n0\n0.5928\n0\n55\n\n\nRain.at.900\nint\n0\nRainfall at 900m altitude (in mm or binary indicator), affecting snow melt.\n0\n0\n0\n0\n0\n0.1912\n0\n1\n\n\nSummit.Air.Temp\nnum\nNA\nAir temperature (in °C) at the summit, influencing upper snowpack conditions.\n754\n7.06587949\n-13.4\n-3.6\n-1.3\n-1.24\n0.8\n15\n\n\nSummit.Wind.Dir\nint\nNA\nWind direction (in degrees) at the summit, impacting snow distribution.\n1318\n12.35123231\n-2\n160\n220\n200.1\n250\n2213\n\n\nSummit.Wind.Speed\nint\nNA\nWind speed (in km/h or mph) at the summit, affecting snow transport.\n909\n8.51841439\n-8\n14\n25\n27.89\n38\n360\n\n\nMax.Temp.Grad\nnum\n20\nMaximum temperature gradient (in °C) across the snowpack, indicating instability.\n710\n6.653547\n0\n0\n0.2\n1.211\n1\n130\n\n\nMax.Hardness.Grad\nint\n4\nMaximum hardness gradient within the snowpack, reflecting layer differences.\n629\n5.89448037\n0\n1\n2\n2.037\n3\n5\n\n\nNo.Settle\nint\nNA\nNumber of days since the last significant snowfall, affecting settlement.\n289\n2.70827476\n-1\n54\n128\n139.1\n206\n676\n\n\nSnow.Index\nint\nNA\nAn index or score related to snowpack stability or quality (specific method unclear).\n745\n6.98153875\n-1\n0\n0\n1.786\n0\n368\n\n\nInsolation\nint\nNA\nSolar radiation or insolation impact (in hours or intensity), affecting snow melt.\n507\n4.75119483\n-55\n3\n6\n7.594\n10\n208\n\n\nCrystals\nint\nNA\nType or size of snow crystals observed, influencing avalanche risk.\n988\n9.25873864\n-1\n0\n0\n1.45\n0\n15\n\n\nWetness\nint\nNA\nDegree of snow wetness (scale or percentage), impacting stability.\n576\n5.39780714\n-1\n1\n1\n1.414\n2\n10\n\n\nAV.Cat\nint\nNA\nAvalanche Category, likely a classification of avalanche type or severity.\n2494\n23.37175522\n-9999\n0\n0\n-321.7\n0\n8800\n\n\nSnow.Temp\nnum\nNA\nTemperature (in °C) within the snowpack, critical for stability assessment.\n410\n3.84218911\n-13.1\n-2.2\n-0.4\n-0.7149\n0\n124\n\n\n\n{.table .table-bordered .table-striped .table-hover}"
  },
  {
    "objectID": "llm-reflection.html",
    "href": "llm-reflection.html",
    "title": "LLM Usage and Reflection",
    "section": "",
    "text": "Our group extensively utilized multiple artificial intelligence tools throughout this avalanche prediction neural network project, employing a systematic and transparent approach to AI integration. The tools included Claude (Sonnet and Opus versions) by Anthropic, ChatGPT-5 by OpenAI and Grok by xAI. All interactions were documented and archived in a dedicated Claude project for complete traceability*.\n\nClaude projects on the Claude Pro plan cannot be made available to the public (projects can be shared publicly on the Enterprise plan). However, links to the individual chats can be shared publicly. A sample of chat are shared below in Appendix A."
  },
  {
    "objectID": "llm-reflection.html#ai-statement",
    "href": "llm-reflection.html#ai-statement",
    "title": "LLM Usage and Reflection",
    "section": "",
    "text": "Our group extensively utilized multiple artificial intelligence tools throughout this avalanche prediction neural network project, employing a systematic and transparent approach to AI integration. The tools included Claude (Sonnet and Opus versions) by Anthropic, ChatGPT-5 by OpenAI and Grok by xAI. All interactions were documented and archived in a dedicated Claude project for complete traceability*.\n\nClaude projects on the Claude Pro plan cannot be made available to the public (projects can be shared publicly on the Enterprise plan). However, links to the individual chats can be shared publicly. A sample of chat are shared below in Appendix A."
  },
  {
    "objectID": "llm-reflection.html#phases-of-ai-utilization",
    "href": "llm-reflection.html#phases-of-ai-utilization",
    "title": "LLM Usage and Reflection",
    "section": "Phases of AI Utilization",
    "text": "Phases of AI Utilization\nAI tools supported key stages of our data science workflow:\n\nExploratory Data Analysis (EDA): Assisted in identifying trends and patterns in the Scotland avalanche forecasts dataset.\nModel Development and Preprocessing: Provided guidance on handling missing data imputation, outlier detection/treatment, and class imbalance. Suggested methods included median imputation by geographic area for numerical variables, mode imputation by area for categorical variables, and context-specific outlier thresholds (e.g., capping altitude at Scotland’s highest peak of 1,345m).\nCode Development: Generated comprehensive R code using keras3 and TensorFlow, based on our EDA findings and requirements. Key prompts covered outlier assessment, missing value strategies, model architecture (including Random Forest feature selection and hyperparameter tuning via grid search), and data splitting (e.g., adjusting from 80/10/10 to 70/15/10 ratios). Also aided debugging, such as transitioning from manual upsampling to ROSE techniques.\nReport Writing and Review: Helped draft analysis sections, interpret evaluation metrics, and perform proofreading, spell-checking, and grammar verification.\n\nWe maintained critical oversight: All AI-generated content was verified against avalanche forecasting literature and Scottish meteorological standards, with code tested for functionality in our dataset context."
  },
  {
    "objectID": "llm-reflection.html#benefits-and-verification",
    "href": "llm-reflection.html#benefits-and-verification",
    "title": "LLM Usage and Reflection",
    "section": "Benefits and Verification",
    "text": "Benefits and Verification\nAI integration offered substantial advantages: - Accelerated timelines and exposure to advanced techniques. - Comprehensive code documentation and creative problem-solving.\nAccuracy was verified through: - Cross-referencing with peer-reviewed research. - Systematic code testing and manual spot-checks. - Comparing outputs across tools for inconsistencies. - Domain-specific evaluation of methodologies."
  },
  {
    "objectID": "llm-reflection.html#critical-reflection",
    "href": "llm-reflection.html#critical-reflection",
    "title": "LLM Usage and Reflection",
    "section": "Critical Reflection",
    "text": "Critical Reflection\nAI tools demonstrated significant strengths but also limitations:\n\nAdvantages: Excelled in generating syntactically correct code and providing creative solutions, enhancing efficiency and innovation.\nLimitations: Occasionally suggested technically sound but contextually unsuitable approaches, lacking nuance in domain-specific factors (e.g., Scottish mountain meteorology). Different tools sometimes gave conflicting advice, requiring synthesis and judgment.\n\nUltimately, AI serves as a powerful assistant but cannot replace human critical thinking, domain expertise, or methodological rigor. This project highlighted the importance of thoughtful, transparent AI use to amplify capabilities while maintaining control."
  },
  {
    "objectID": "llm-reflection.html#llm-prompt-links",
    "href": "llm-reflection.html#llm-prompt-links",
    "title": "LLM Usage and Reflection",
    "section": "LLM prompt links",
    "text": "LLM prompt links\n\nChats from Claude\nEDA\nOutlier Analysis\nNaN analsis\nFeature Selection\nModel Development\nModel Development\nModel Debugging\n\n\nChats from Grok\n\n\nChats from ChatGPT"
  }
]