[
  {
    "objectID": "paper.html",
    "href": "paper.html",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "Avalanche forecasting integrates mountain meteorology, snowpack physics, terrain analysis, and risk communication to reduce loss of life and support safer winter travel. In Scotland, the Scottish Avalanche Information Service (SAIS) publishes daily next-day hazard assessments across six high-mountain regions during winter which draws upon field observations, snowpack tests and weather guidance (Scottish Avalanche Information Service [SAIS], n.d.). This report contributes a data-driven complement to that long-running operational effort. Our task is defined as to construct and evaluate a neural network model that predicts the forecasted avalanche hazard (FAH).\nThis research isn’t meant to replace expert judgment. It gives forecasters a second opinion that consistently flags risky combinations of weather, terrain, and snowpack variables. In Scotland’s maritime, wind-dominated winters with frequent storm cycles and rapid thaw freeze shifts this kind of decision support sharpens situational awareness and strengthens risk communication (SAIS, n.d.; EAWS, n.d.)."
  },
  {
    "objectID": "paper.html#introduction",
    "href": "paper.html#introduction",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "",
    "text": "Avalanche forecasting integrates mountain meteorology, snowpack physics, terrain analysis, and risk communication to reduce loss of life and support safer winter travel. In Scotland, the Scottish Avalanche Information Service (SAIS) publishes daily next-day hazard assessments across six high-mountain regions during winter which draws upon field observations, snowpack tests and weather guidance (Scottish Avalanche Information Service [SAIS], n.d.). This report contributes a data-driven complement to that long-running operational effort. Our task is defined as to construct and evaluate a neural network model that predicts the forecasted avalanche hazard (FAH).\nThis research isn’t meant to replace expert judgment. It gives forecasters a second opinion that consistently flags risky combinations of weather, terrain, and snowpack variables. In Scotland’s maritime, wind-dominated winters with frequent storm cycles and rapid thaw freeze shifts this kind of decision support sharpens situational awareness and strengthens risk communication (SAIS, n.d.; EAWS, n.d.)."
  },
  {
    "objectID": "paper.html#background",
    "href": "paper.html#background",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "Background",
    "text": "Background\nScotland’s avalanche forecasts are produced by the Scottish Avalanche Information Service (SAIS). The SAIS conducts daily fieldwork, snow profiles, stability tests and terrain analysis that is blended with meteorological guidance to issue next-day public danger ratings, snowpack summaries and travel advice. This information spans Torridon, Northern Cairngorms, Southern Cairngorms, Creag Meagaidh, Lochaber, and Glencoe. The communication follows the standard EAWS danger scale to keep messages consistent and comparable.\nAvalanches are rapid snow flows that can contain ice, rock, and vegetation. The most dangerous to travellers are slab avalanches, where a cohesive slab slides on a weaker layer once shear strength is exceeded by gravitational and external loading. The triggers for an avalanche may be natural (snowfall, wind loading, warming) or manmade (a skier, climber, or snowmobile). These avalanches most often occur on slopes around 34–45 degrees. In Scotland’s maritime, wind-dominated winters wind slabs are common (Schweizer, Jamieson, & Schneebeli, 2003).\nAvalanche forecasting looks to improving consistency, calibration, and timeliness of hazard assessments which can essentially save lives and reduce societal costs. In Europe, despite substantial growth in backcountry participation, the long-term average annual avalanche fatality count has remained broadly steady at 100 per year across the Alps. This is attributed in part to better education, equipment, and forecasting (Techel et al., 2016). Scotland’s totals are smaller, but fatal and non-fatal involvements recur most winters and SAIS seasonal reports routinely document hundreds of observed avalanches (SAIS, n.d.). The impacts however extend beyond casualty numbers as they tend to disrupt transport, tourism, and emergency services."
  },
  {
    "objectID": "paper.html#dataset",
    "href": "paper.html#dataset",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "Dataset",
    "text": "Dataset\nThe dataset is an operational archive produced by the Scottish Avalanche Information Service (SAIS). It spans approximately fifteen winter seasons and reflects real-time fieldwork. Forecasters collect these records in severe weather environments and under time constraints. As a result, the data shows uneven sampling across storm cycles and regions, along with missing entries during periods of limited access.\nThe feature set can be categorised into five distinct groups that collectively capture the multifaceted nature of avalanche risk assessment:\nSpatial and Temporal Features include Date, Area, longitude, latitude, and altitude, which establish the geographical and temporal context of each observation. These variables are crucial for understanding regional variations in avalanche conditions and seasonal patterns across Scotland’s diverse mountain terrain.\nTopographical Features encompass Aspect and Incline, which directly influence avalanche susceptibility. Slope angle determines the gravitational stress on the snowpack, while aspect affects wind loading, solar exposure, and temperature variations that influence snow stability.\nMeteorological Features comprise a comprehensive set of weather observations including air temperature, wind direction and speed (both at observation level and summit), cloud cover, precipitation codes, and insolation. These variables capture the atmospheric conditions that drive snow accumulation, redistribution, and metamorphism processes fundamental to avalanche formation.\nSnowpack Physical Properties include total snow depth, foot and ski penetration measurements, snow temperature, crystal characteristics, wetness levels, and drift indicators. These features provide direct measures of snowpack structure, density, and mechanical properties that determine stability and failure potential.\nSnowpack Stability Indicators encompass specialised measurements such as temperature and hardness gradients, settlement patterns, and composite indices like Snow.Index and AV.Cat. These derived metrics capture the complex internal structure and stress distribution within the snowpack that directly relate to avalanche hazard assessment [@anthropic2024claude].\nBy relating these predictors to FAH the model can learn recurrent, non-linear patterns. It highlights situations where higher hazard is more likely, so forecasters can focus their checks and make cleaner day-to-day calls (EAWS, n.d.; SAIS, n.d.)."
  },
  {
    "objectID": "paper.html#methodology",
    "href": "paper.html#methodology",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "Methodology",
    "text": "Methodology\nThis solution developed a supervised neural network classifier to predict next-day FAH using 16 years of SAIS operational data. The methodology followed a systematic machine learning pipeline implemented in R with reproducibility ensured through fixed random seeds.\nThe dataset underwent comprehensive exploratory data analysis to assess missing data patterns, outlier distributions, and class imbalances. Non-predictive variables (observed avalanche hazard, observer identifiers, and location codes) were removed to prevent data leakage. Observations with missing target values were excluded, and FAH categories were standardized into five ordinal risk levels: Low, Moderate, Considerable-, Considerable+, and High. Statistical outlier detection using the interquartile range method combined with domain-specific constraints removed physically implausible values while preserving legitimate extreme weather events.\nNew meteorologically meaningful variables were created, including wind chill indices, temperature gradients, snow-altitude interactions, and trigonometric aspect transformations. Temporal features (month, day of year, season) captured seasonal avalanche patterns. A multi-method feature selection approach combined LASSO regularisation, Random Forest importance scoring, and correlation analysis to identify the 25 most predictive variables using weighted composite scores.\nThe dataset was split into training (70%), validation (15%), and test (15%) sets using stratified sampling to maintain class proportions. To address severe class imbalance (original ratio 7.2:1), the Random Over-Sampling Examples (ROSE) technique was applied exclusively to training data using a one-versus-rest strategy, reducing imbalance to approximately 1.2:1 while preserving natural distributions in evaluation sets.\nA three-layer deep neural network was implemented using Keras/TensorFlow with progressive layer sizes (256→128→64 neurons), batch normalization for training stability, and dropout regularization (rates: 0.3, 0.4, 0.5) to prevent overfitting. The model employed categorical crossentropy loss with Adam optimization and incorporated Gaussian noise injection for additional regularisation. Hyperparameter tuning evaluated three configurations, selecting the optimal based on validation accuracy.\nThe final model was trained for up to 150 epochs with early stopping and learning rate reduction callbacks. Evaluation employed both standard multiclass metrics (accuracy, precision, recall, F1-score) and ordinal-specific measures including adjacent accuracy (±1 level), mean absolute error, and safety-critical metrics such as conservative bias and critical miss rates. This comprehensive evaluation framework assessed both predictive performance and operational safety implications for avalanche forecasting.\nWe used large language models (LLMs) to accelerate routine coding tasks. Each team member supplied an LLM with a structured brief (data schema, variable descriptions, target definition, leakage constraints, evaluation metrics) to draft boilerplate R code for preprocessing, imputation functions, model scaffolding (keras3), and plotting. To promote diversity of ideas and reduce single-model bias, different teammates intentionally used different LLMs. This use of LLMs sped up drafting, but final code, methodological choices, and validation remained human-curated. Our detailed statement on the use of generative artifical intelligence (AI) is included in LLM Usage and Reflection. In the next section, we initiated exploratory data analysis (EDA) before developing our model."
  },
  {
    "objectID": "paper.html#exploratory-data-analysis",
    "href": "paper.html#exploratory-data-analysis",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nThis section of the report examines the key characteristics of the Scottish avalanche forecast dataset to inform modeling decisions and identify potential challenges. In particular, it investigates the distribution and balance of the target variable (FAH), assesses missing data patterns across all variables to guide preprocessing strategies, and explores temporal coverage to understand seasonal patterns and data collection consistency.\n\nTarget Variable Distribution\nThis section examines the distribution of our target variable (FAH) to understand class balance and identify potential modeling challenges that arise from the natural rarity of high-risk avalanche conditions.\n\n\n\n\n\n\nFigure 1: FAH Distribution\n\n\n\nFrom Figure 1, we observe that the FAH target variable exhibits severe class imbalance, with safer classes dominating the distribution: Low and Moderate together account for approximately 63% of observations, while Considerable- is moderately represented at 23.6%. In contrast, the higher-risk classes i.e., Considerable+ and especially High are rare. This skew implies that a model could achieve high overall accuracy by favoring common classes i.e., naive classification, while failing to detect infrequent but critical high-hazard events. To mitigate this, we later employ ROSE balancing.\n\n\nMissing Data Analysis\nThis section assesses missing data patterns across all variables to identify problematic predictors and inform data quality decisions for preprocessing.\n\n\n\n\n\n\nFigure 2: Missing data analysis graph\n\n\n\nFrom Figure 2, the missing data diagnostics reveal that AV_Cat and Ski_Pen exhibit the highest gaps (≈20%+), prompting their removal from the dataset during preprocessing. Following these, a cluster of snowpack microstructure and condition variables (e.g., Crystals, Wetness, No Settle) show moderate missingness, alongside certain wind-direction and temperature fields. Therefore, we implemented data imputation techniques to account for the missing data in these features. The target variable FAH has negligible missingness; however, we removed observations with missing data in the target variable.\n\n\nData Quality Issues & Outliers\nOur outlier analysis during EDA revealed significant data quality issues across multiple features. Altitude measurements contained two extreme outliers (244,859m and 77,044m) that were physically impossible given Scotland’s topography, where the highest peak reaches only 1,345m. Aspect measurements included values exceeding 163,770 degrees, far beyond the valid compass range of 0-360 degrees. Wind speed data exhibited a broad range from negative values to 290 km/h, with summit wind speeds reaching up to 360 km/h—values that likely represent measurement errors rather than genuine hurricane-force conditions in Scottish mountains. Snow depth measurements displayed extreme variability, ranging from negative values to an implausible maximum of 3,000cm (30 metres), significantly exceeding typical Scottish mountain snow accumulation patterns. Cloud cover data contained impossible values, including negative percentages and readings up to 199%, exceeding the theoretical maximum of 100%. Both foot and ski penetration measurements included negative values, with foot penetration ranging up to 300cm and ski penetration reaching 55cm. Incline data spanned from negative values to 1,020 degrees, with numerous observations exceeding 90 degrees. Extreme values were addressed through a combination of IQR-based removal for most variables and domain-specific thresholds for others, with negative values corrected to zero and upper limits applied based on physical plausibility within the Scottish mountain context.\n\n\nTemporal Analysis\nThis section examines the temporal distribution of observations to understand seasonal patterns, data collection consistency, and potential time-based features for modeling.\n\n\n\n\n\n\nFigure 3: Temporal analysis graphs\n\n\n\nFrom Figure 3, it can be observed that the dataset spans from 2009 to 2025, providing 16 years of avalanche forecasting data with remarkable consistency. The monthly distribution reveals the expected strong seasonal concentration, with the vast majority of observations occurring during winter months (December through March). Summer months (May through November) show minimal or zero activity, which aligns perfectly with avalanche season expectations in Scottish mountains where snow conditions are primarily a winter phenomenon. These temporal patterns supported the inclusion of seasonal and monthly features in our neural network model, as demonstrated in the feature engineering section Feature Engineering.\n\n\nComparison of Actual and Predicted Observations\nThis section evaluates the relationship between forecast and observed avalanche hazard levels to establish baseline performance expectations and identify inherent prediction challenges.\n\n\n\n\n\n\nFigure 4: Graph comparing FAH versus OAH pairs\n\n\n\nFrom Figure 4, which analyses FAH versus OAH pairs as a verification benchmark for forecast reliability, we observe an overall accuracy of approximately 70–75%. Per-class performance varies notably: accuracy is highest for Low risk (mid-90s%), followed by Moderate (70%), then decreases for Considerable- (60–70%), drops substantially for Considerable+ (35%), and improves slightly for High (~45%). This pattern suggests that forecasters—and by extension, predictive models—struggle most with distinguishing adjacent hazard boundaries. Accordingly, our model evaluation emphasises ordinal metrics such as adjacent accuracy (±1 level), critical-miss rate (underpredicting high risk), and high-risk sensitivity to ensure practical utility in avalanche forecasting.\n\n\nCorrelation analysis\nThis section evaluates the correlations between the features as well as the correlations between the features and the output.\n\n\n\n\n\n\nFigure 5: Correlation heatmap\n\n\n\nThe correlation heatmap in Figure 5 reveals coherent but mostly moderate correlation clusters among variables. Notably, temperature features (Air temperature, and summit air temperature) exhibit strong covariation, while cloud and insolation show the expected inverse relationship. Wind speeds correlate across levels with some directional noise, and penetration/strength metrics (Foot penetration and ski penetration depth) associate with total snow depth in predictable ways. Meanwhile, maximum temperature gradient and maximum hardness gradient relate to temperature and snow-structure variables through more complex mechanisms, likely tied to metamorphic processes in the snowpack. Overall, this indicates potential multicollinearity, particularly among thermodynamic and wind features, which could destabilise linear models and hinder neural network convergence. To address this, we implemented ensemble feature selection combining LASSO regularisation, random forest importance scoring, and correlation-based filtering to minimise redundancy.\n\n\nEDA Conclusion\nThe target variable (FAH) exhibits severe class imbalance, with safer conditions (Low and Moderate) dominating approximately 63% of observations whilst higher-risk categories (Considerable+ and High) remain rare. To address this imbalance, ROSE sampling was applied to the training data using a one-versus-rest strategy, generating synthetic samples to achieve more balanced class distributions whilst preserving natural distributions in validation and test sets. Missing data patterns reveal structured gaps rather than random missingness. Variables AV.Cat and Ski.Pen show the highest missingness rates (&gt;20%), prompting their removal during preprocessing. Additional moderate gaps appear in snowpack microstructure variables and certain meteorological fields, leading to the implementation of imputation strategies for missing data. The temporal analysis confirms expected seasonal patterns, with observations concentrated heavily in winter months (December-March) across a consistent 16-year span from 2009-2025. This seasonal clustering directly motivated the creation of temporal features including month, day of year, and season variables, whilst the stable annual collection volumes validate the dataset’s temporal consistency for model training. Forecast verification analysis comparing FAH versus OAH reveals overall accuracy of approximately 70-75%, with performance varying substantially across risk levels. Accuracy peaks for Low risk conditions (mid-90s%) but deteriorates progressively through higher-risk categories, reaching lowest levels for Considerable+ (35%). This pattern highlights the inherent difficulty in distinguishing adjacent hazard boundaries, directly informing the adoption of ordinal-specific evaluation metrics including adjacent accuracy (±1 level), critical miss rates, and high-risk sensitivity measures rather than relying solely on overall classification accuracy. The following section discusses our data refinement stategy."
  },
  {
    "objectID": "paper.html#data-refinement",
    "href": "paper.html#data-refinement",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "Data Refinement",
    "text": "Data Refinement\nThe raw Scottish avalanche forecast dataset required systematic preprocessing to ensure reliable neural network training whilst preserving the meteorological and topographical signals essential for hazard prediction. Our data refinement approach balanced the competing demands of maintaining data integrity and achieving computational tractability, recognising that avalanche conditions exhibit strong spatial and temporal dependencies that must be preserved throughout the cleaning process. The following subsections detail our systematic approach to feature removal, outlier detection, feature engineering, missing value imputation, target encoding, feature selection, and class balancing, culminating in a refined dataset of 7,530 complete observations suitable for robust neural network training and evaluation.\n\nFeature Removal\nOur preprocessing commenced with the removal of non-predictive administrative fields, specifically OAH (observed avalanche hazard) and Obs (observer identifier), since our objective focused on predicting forecasted rather than observed conditions. In addition, after the imputation section, we removed non-predictive features i.e., Date, OSgrid and location.\nWe eliminated 109 observations lacking FAH values, leaving 10 562 viable records. Missing data analysis exposed significant gaps in AV.Cat (23.4%) and Ski.Pen (22.5%), which we excluded to avoid unreliable imputation. The remaining variables exhibited structured rather than random missingness patterns, with core meteorological and topographical measurements showing minimal gaps (≤3%), supporting our subsequent contextual imputation approach.\n\n\nOutlier Removal\nOur outlier removal strategy involved a dual-tier outlier detection protocol compining statistical principles with domain expertise. Initially, we converted string representations of missing values to proper NA indicators and applied robust Interquartile Range filtering (with a swift scalar parameter of k=3.5) to meteorological variables prone to measurement errors i.e.:\n\nAlt (2)\nWind.Speed (22)\nSummit.Wind.Speed (81)\nTotal.Snow.Depth (111)\nAir.Temp (1)\n\nFoot.Pen (34)\n\nSubsequently, we enforced physical plausibility constraints, removing Aspect measurements exceeding 360 degrees (8 cases), constraining Cloud coverage to 0-100% (3 cases), and limiting Incline to physically realistic slopes between 0-90 degrees (5 cases). This conservative approach eliminated 267 observations (2.53% of the dataset) whilst preserving legitimate extreme weather events that provide crucial signal for hazard prediction. The methodology successfully removed erroneous readings that would distort feature scaling and hinder neural network optimisation, without sacrificing valuable information about genuine storm conditions.\n\n\nFeature Engineering\nWe developed five engineered features that encode avalanche formation mechanisms directly into the predictor space. Wind chill, calculated as air temperature minus 0.6 times wind speed, approximates near-surface cooling effects that influence snowpack stability under windy conditions. Temperature gradient, representing the difference between summit air temperature and air temperature, captures atmospheric stability and potential for snow transport processes. Snow altitude interaction multiplies total snow depth by altitude scaled to kilometres, reflecting elevation-dependent snow accumulation patterns and rain-snow transition zones. Recognising the circular nature of compass bearings, we transformed aspect into orthogonal components i.e., aspect north using cosine transformation and aspect east using sine transformation, eliminating artificial discontinuities at 360° and 0°. Temporal features i.e., Month, day, and season were extracted to capture the pronounced seasonal patterns evident in the EDA, enabling the network to learn both inter- and intra-seasonal risk variations.\n\n\nImputation for Missing Values\nMissing value imputation employed a hierarchical approach reflecting the spatial and temporal structure of avalanche conditions. We employed area and seasonal medians to impute missing values in numerical features, while categorical features were imputed using modal values. This ensures replacement values reflect typical conditions for specific regions and seasons rather than dataset-wide averages that could misrepresent local climate patterns.\n\n\nEncoding\nThe next step in our model involved encoding encoded categorical features and the target variable. Target encoding transformed the categorical FAH variable into an ordinal integer sequence (Low=0, Moderate=1, Considerable-=2, Considerable+=3, High=4), preserving the natural risk hierarchy essential for ordinal classification evaluation. For predictors, we cleaned categorical fields and applied a frequency threshold (≥50) so very rare levels were folded into “Other” to limit sparsity.\n\n\nFeature Selection\nThe model implements a comprehensive feature selection process. The process begins by separating features from the target variable and standardising numerical features using centre and scale normalisation to ensure all variables are on comparable scales. The model employs a multi-method approach that combines three different feature selection techniques to create a robust scoring framework. First, it uses LASSO regularisation with cross-validation to identify features with non-zero coefficients, scoring them based on the absolute magnitude of their coefficients. Second, it applies Random Forest to evaluate feature importance, though it limits the analysis to the top 50 most correlated features if the dataset is too large. Finally, it calculates correlation-based scores by measuring the absolute correlation between each feature and the target variable.\nThe innovative aspect of this approach lies in its composite scoring system, which weights each method’s contributions (LASSO 30%, Random Forest 40%, and correlation 30%) and provides a bonus for features that perform well across multiple methods. Features selected by more methods receive higher total scores through a multiplicative bonus factor. The process concludes by ranking all features according to their composite scores and selecting the top 25 features for subsequent modelling. This methodology ensures that the selected features are not only individually predictive but also consistently identified across different selection techniques, potentially leading to more robust model performance.\n\n\nStratified Splitting and Class Balance Correction\nThe refined dataset of 7 530 observations underwent stratified partitioning to maintain proportional class representation across training (70%, 5,273 samples), validation (15%, 1,129 samples), and test (15%, 1,128 samples) sets. This preserved the natural class imbalance for realistic evaluation whilst ensuring adequate representation of each hazard level.\nClass imbalance in the training set showed a severe 12.4:1 ratio between majority and minority classes, necessitating corrective sampling. We applied ROSE exclusively to training data post-split to prevent data leakage, using an iterative one-versus-rest strategy to accommodate ROSE’s binary classification requirement. Synthetic samples were generated for minority classes until reaching approximately 95% of majority class size, avoiding perfect balance that might introduce artificial patterns.\nThe enhanced training set expanded from 5,273 to 8,641 observations with roughly 1,700 samples per class, reducing imbalance to 1.05:1 (91.5% improvement). This substantial rebalancing provides the neural network with sufficient minority class examples for effective learning whilst maintaining natural class distributions in validation and test sets for unbiased performance evaluation.\n\n\nNeural Network Architecture\nAfter hyperparameter tuning across three candidate configurations, the optimal network achieved a validation accuracy of 0.6138 with a corresponding training accuracy of 0.7159. This represented the best trade-off between learning capacity and generalisation. The final architecture consisted of three hidden layers with 512, 256, and 128 units, respectively, paired with progressively increasing dropout regularisation (0.20, 0.30, 0.40). Gaussian noise was applied at the input layer to mitigate overfitting and improve robustness against noisy environmental predictors. The network was trained using the Adam optimiser with a learning rate of 5×10⁻⁴ and a batch size of 32, which provided stable convergence during training.\n\n\n\nLayer\nUnits\nDropout\nNotes\n\n\n\n\nInput\n–\n–\n25 selected features\n\n\nHidden Layer 1\n512\n0.20\nDense + BatchNorm + GaussianNoise\n\n\nHidden Layer 2\n256\n0.30\nDense + BatchNorm + Dropout\n\n\nHidden Layer 3\n128\n0.40\nDense + BatchNorm + Dropout\n\n\nOutput\n5\n–\nSoftmax (multiclass, ordinal)\n\n\n\nTable 1: Final neural network architecture\nThe training and validation curves showed that the model achieved stable convergence, though validation accuracy plateaued around 0.61, reflecting the intrinsic difficulty of predicting the rare high-risk classes."
  },
  {
    "objectID": "paper.html#model-performance-evaluation",
    "href": "paper.html#model-performance-evaluation",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "Model Performance Evaluation",
    "text": "Model Performance Evaluation\n\nOverall Performance\nThe neural network’s performance was assessed across the training, validation, and test datasets to evaluate both its learning capacity and generalisation ability. During training, the model achieved a best training accuracy of 71.6%, with the corresponding best validation accuracy reaching 61.4%. The final test accuracy was 60.6% (loss = 0.993). The gap between training and validation performance indicates some overfitting, which is expected in complex models, but the close alignment of validation and test results shows that the network generalised reasonably well to unseen data and avoided substantial performance degradation.\nBeyond test accuracy, complementary metrics provided deeper insight into generalisation. Macro-averaged scores (precision = 0.499, recall = 0.452, F1 = 0.459) showed that the model was only moderately effective when treating all classes equally. Weighted averages were higher (precision = 0.589, recall = 0.606, F1 = 0.594), reflecting stronger performance on the dominant classes. Cohen’s Kappa, at 0.443, placed the model in the “moderate agreement” range, showing that predictions were significantly better than random guessing but not yet highly reliable. EDA findings again provide explanation: the removal of several snowpack variables with &gt;20% missingness reduced the depth of predictive features, while extreme but plausible outliers (e.g., very high winds, deep snowpack events) complicated the learning process, particularly for rarer hazard categories.\nGiven the ordinal nature of avalanche hazard levels, error magnitudes were as important as raw accuracy. Predictions deviated by an average of only 0.45 hazard levels (MAE), with relatively low dispersion (RMSE = 0.765; MSE = 0.585). Adjacent accuracy was exceptionally high (94.5% within ±1 level), while extreme misclassifications were nearly absent (99.5% within ±2 levels; 100% within ±3 levels). These findings confirm that catastrophic errors (e.g., predicting Low when the true level was High) were virtually eliminated. This aligns with EDA evidence showing that extreme meteorological conditions such as heavy snowfall or very strong winds rarely overlapped with Low hazard conditions, providing the model with clearer separation at the extremes.\nFinally, correlation-based metrics confirmed that the network preserved the ordinal structure of avalanche hazard levels. Strong monotonic associations were observed (Spearman’s ρ = 0.738, Pearson r = 0.723), with Kendall’s Tau (0.670, p &lt; 0.001) and directional accuracy (0.718) showing that the ordering of predicted hazard levels was largely consistent with the true sequence. Together, these results show that while the model achieved only moderate exact-match classification accuracy, it maintained ordinal consistency, avoided severe misclassifications, and delivered meaningful improvements over baseline predictors.\n\n\n\nMetric\nValue\n\n\n\n\nTraining Accuracy\n0.716\n\n\nValidation Accuracy\n0.614\n\n\nTest Accuracy\n0.606\n\n\nTest Loss\n0.993\n\n\nMacro Precision\n0.499\n\n\nMacro Recall\n0.452\n\n\nMacro F1-Score\n0.459\n\n\nWeighted Precision\n0.589\n\n\nWeighted Recall\n0.606\n\n\nWeighted F1-Score\n0.594\n\n\nCohen’s Kappa\n0.443\n\n\nMean Absolute Error (MAE)\n0.454\n\n\nRoot Mean Squared Error (RMSE)\n0.765\n\n\nMean Squared Error (MSE)\n0.585\n\n\nAdjacent Accuracy (±1 level)\n0.945\n\n\nWithin-2 Accuracy (±2 levels)\n0.995\n\n\nWithin-3 Accuracy (±3 levels)\n1.000\n\n\nSpearman’s ρ\n0.738\n\n\nPearson r\n0.723\n\n\nKendall’s Tau\n0.670\n\n\nDirectional Accuracy\n0.718\n\n\n\nTable 2: Overall Performance Metrics of the Neural Network\n\n\nConfusion Matrix and Class-Level Performance\nThe confusion matrix offered a clear breakdown of how the model performed across individual hazard levels. For the Low hazard class, the network achieved strong results (sensitivity = 0.836, precision = 0.723, F1 = 0.775), reflecting consistent identification of stable snowpack conditions. This strength is consistent with EDA findings, which showed that Low days were associated with distinct signals — shallow snow depth, weak drift, and stable temperature gradients — making them easier for the model to separate. Similarly, the Moderate class reached moderate reliability (sensitivity = 0.540, precision = 0.578, F1 = 0.558), supported by its high prevalence in the dataset and relatively consistent meteorological profiles. Together, these two classes accounted for most correct predictions, reflecting both their dominance in the dataset and their clearer predictor signatures.\nThe Considerable– class performed less consistently (precision = 0.526, recall = 0.553, F1 = 0.539). Misclassifications were concentrated between adjacent levels: 79 cases confused with Moderate and 20 with Considerable+. This behavior aligns with the transitional nature of predictors highlighted in the EDA, where snow depth, crystal type, and summit air temperature overlapped substantially between Moderate and Considerable– categories.\nPerformance deteriorated sharply for the Considerable+ and High hazard levels, which achieved very low recall (0.241 and 0.091, respectively) and correspondingly low F1-scores (0.280 and 0.143). High cases were most often misclassified as Considerable– (14 cases) or Considerable+ (15 cases), but crucially, none were mistaken for Low. This indicates that while the model struggled to distinguish among upper hazard levels, it preserved ordinal structure and avoided catastrophic misclassifications. The EDA findings explain this limitation: these rare categories comprised less than 5% of the dataset and were characterised by overlapping meteorological signals such as heavy snowfall, wind drift, and deep weak layers. With limited training samples, the network could not fully disentangle these patterns.\nThe per-class F1-scores reflected this gradient in performance: Low (0.775) and Moderate (0.558) were acceptable, Considerable– was moderate (0.539), while Considerable+ (0.280) and High (0.143) were poor. These values highlight the central trade-off of the model: strong utility in predicting stable and moderately unstable conditions, but weak reliability in capturing rare but operationally critical high-risk categories.\n\n\n\n\n\n\n\n\n\n\n\nPredicted  Actual\nLow\nModerate\nConsiderable –\nConsiderable +\nHigh\n\n\n\n\nLow\n315\n105\n11\n5\n0\n\n\nModerate\n55\n205\n79\n15\n1\n\n\nConsiderable –\n7\n65\n141\n41\n14\n\n\nConsiderable +\n0\n5\n20\n20\n15\n\n\nHigh\n0\n0\n4\n2\n3\n\n\n\nTable 3: Confusion Matrix of Predicted vs Actual Avalanche Hazard Levels\n\n\n\nClass\nPrecision\nRecall\nF1-Score\nSupport\n\n\n\n\nLow\n0.723\n0.836\n0.775\n377\n\n\nModerate\n0.578\n0.540\n0.558\n380\n\n\nConsiderable –\n0.526\n0.553\n0.539\n255\n\n\nConsiderable +\n0.333\n0.241\n0.280\n83\n\n\nHigh\n0.333\n0.091\n0.143\n33\n\n\n\nTable 4: Precision, Recall, and F1-Score by Avalanche Hazard Class\n\n\nConfidence-Based Reliability\nMost predictions were made with low confidence (≤0.6, 62.9%), while 23.0% were medium (0.6–0.8) and only 14.1% were high (&gt;0.8). Prediction accuracy scaled with confidence: 88.7% at high confidence, 65.3% at medium, and 52.7% at low confidence. At the class level, Low hazard predictions averaged the highest confidence (0.708) with strong accuracy (83.6%), while Moderate (0.551) and Considerable– (0.511) showed low confidence and middling reliability.Predictions for Considerable+ (0.527) and High (0.584) carried similarly low confidence but were far less accurate (24.1% and 9.1%, respectively), highlighting systematic difficulty with rare high-risk categories. These results confirm that prediction probabilities provided a meaningful gradient of reliability, with higher confidence strongly associated with higher accuracy.\n\n\n\nConfidence Level\nAccuracy\n\n\n\n\nHigh (&gt; 0.8)\n88.7%\n\n\nMedium (0.6–0.8)\n65.3%\n\n\nLow (≤ 0.6)\n52.7%\n\n\n\nTable 5: Accuracy of Predictions by Confidence Level\n\n\n\nConfidence Level\nAccuracy\n\n\n\n\nHigh (&gt; 0.8)\n88.7%\n\n\nMedium (0.6–0.8)\n65.3%\n\n\nLow (≤ 0.6)\n52.7%\n\n\n\nTable 6: Accuracy of Predictions by Confidence Level\n\n\nAvalanche-Specific Safety Metrics\nThe model achieved a Critical Miss Rate of 18.1%, showing that nearly one in five severe avalanche cases (Considerable+ or High) were underestimated as Low or Moderate. Safety Effectiveness reached 74.6%, indicating that in most cases the model predicted at or above the true hazard level. A negative Conservative Bias (–0.114) revealed a mild tendency to underestimate risk overall. High-risk detection showed mixed outcomes: Sensitivity was 70.1%, meaning most but not all severe cases were detected, while Specificity was 89.8%, reflecting strong reliability in avoiding false alarms.\n\n\n\n\n\n\n\n\nMetric\nValue\nInterpretation\n\n\n\n\nCritical Miss Rate\n18.1%\nSevere events underestimated as Low/Moderate\n\n\nSafety Effectiveness\n74.7%\nPredictions at or above true hazard level\n\n\nConservative Bias\n–0.114\nMild overall tendency to underestimate risk\n\n\nHigh-Risk Sensitivity\n70.1%\nAbility to detect Considerable– and above\n\n\nHigh-Risk Specificity\n89.8%\nAbility to avoid false alarms on lower-risk levels\n\n\n\nTable 7: Avalanche-Specific Safety Metrics"
  },
  {
    "objectID": "paper.html#feature-importance-assessment",
    "href": "paper.html#feature-importance-assessment",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "Feature Importance Assessment",
    "text": "Feature Importance Assessment\nThe feature importance analysis revealed that predictors strongly aligned with established avalanche science and EDA findings. Foot Penetration and Drift were the top-ranked features, reflecting their direct links to snowpack weakness and wind-driven slab formation. Key atmospheric drivers — Summit Air Temperature and Total Snow Depth — also ranked highly, confirming their influence on hazard variability observed in the EDA. Crystal Type added further insight into snow microstructure transitions, especially between Moderate and Considerable– categories.\nWind- and temperature-related factors such as Air Temperature, Wind Chill, and Wind Speed consistently scored highly across methods, echoing EDA findings on strong thermal gradients and wind redistribution as critical instability drivers. Seasonal and temporal features — particularly Winter, Day of Year, and Snow–Altitude Interaction — captured the clustering of high hazard levels during winter peaks and at higher elevations. Geographical indicators such as Lochaber and Torridon added spatial context, though with secondary importance.\nIn summary, the most important features reflected a combination of snowpack properties, meteorological drivers, and seasonal patterns, confirming that the model’s predictive behaviour was rooted in meaningful physical processes identified during the exploratory analysis.\n\n\n\n\n\n\nFigure 6: Feature importance graphs"
  },
  {
    "objectID": "paper.html#conclusion-and-recommendations",
    "href": "paper.html#conclusion-and-recommendations",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "Conclusion and Recommendations",
    "text": "Conclusion and Recommendations\nThis study evaluated the application of a neural network model to forecast avalanche hazard levels in Scotland, integrating exploratory data analysis, feature engineering, and rigorous model evaluation.The neural network achieved a training accuracy of 71.6%, a validation accuracy of 61.4%, and a test accuracy of 60.6%, showing good generalisation without major overfitting. While exact classification accuracy was moderate, 94.5% of predictions were within ±1 hazard level, and errors averaged only 0.45 levels, indicating that the model preserved ordinal structure and avoided large-scale misclassifications. Performance was strongest for Low and Moderate hazards but much weaker for rare severe levels (Considerable+ and High), reflected in a Critical Miss Rate of 18.1% and a Safety Effectiveness of 74.6%\nFeature importance confirmed that avalanche risk was primarily driven by snowpack properties (Foot Penetration, Snow Depth, Crystal Type), wind-related processes (Drift, Wind Chill, Wind Speed), and temperature gradients (Summit Air Temperature, Air Temperature), alongside seasonal and regional influences.\nTo improve performance, future work should focus on better representation of high-hazard cases, possibly through expanded datasets or transfer learning. Ensemble methods and uncertainty-based outputs could also increase operational reliability. While not yet suitable as a standalone system, the model shows strong potential as a decision-support tool when combined with expert judgment."
  },
  {
    "objectID": "paper.html#author-contributions",
    "href": "paper.html#author-contributions",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "Author Contributions",
    "text": "Author Contributions\n\nBrendon Pretorius: Formal Analysis, Project Administration, Writing – Review & Editing\nJohan John: Formal Analysis, Writing – Original Draft Preparation\nNabil Patel: Formal Analysis, Methodology, Writing – Original Draft Preparation\nNkateko Mawelele: Formal Analysis, Writing – Original Draft Preparation"
  },
  {
    "objectID": "paper.html#references-apa",
    "href": "paper.html#references-apa",
    "title": "Scientific Paper: Neural Network for Forecasted Avalanche Hazard",
    "section": "References (APA)",
    "text": "References (APA)\nBishop, C. M. (2006). Pattern recognition and machine learning. Springer.\nAnthropic. (2024). Claude Sonnet 4 (December 28 version) [Large language model]. https://claude.ai/chat\nEuropean Avalanche Warning Services. (n.d.). Danger scale and standards. https://www.avalanches.org\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT Press.\nJuvik, E. S. (2023). Toward data-driven decision support for avalanche-exposed roads in Norway. In Proceedings of the International Snow Science Workshop (ISSW 2023). Norwegian Public Roads Administration.\nMcClung, D., & Schaerer, P. (2006). The avalanche handbook (3rd ed.). The Mountaineers Books.\nScottish Avalanche Information Service. (n.d.). About SAIS and daily avalanche reports. https://www.sais.gov.uk\nSchweizer, J., Jamieson, B., & Schneebeli, M. (2003). Snow avalanche formation. Reviews of Geophysics, 41(4), 1–25. https://doi.org/10.1029/2002RG000123\nTechel, F., & Zweifel, B. (2014). Recreational avalanche accidents in Switzerland: Trends and patterns with an emphasis on burial, rescue methods and avalanche danger. Cold Regions Science and Technology, 97, 77–85. https://doi.org/10.1016/j.coldregions.2013.09.006\nTechel, F., Jarry, F., Kronthaler, G., Mitterer, C., Nairz, P., Pavšek, M., Valt, M., & Zweifel, B. (2016). Avalanche fatalities in the European Alps: Long-term trends and perspectives. Cold Regions Science and Technology, 121, 22–31. https://doi.org/10.1016/j.coldregions.2015.11.017"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA5073Z Assignment 1: Avalanche Hazard Prediction",
    "section": "",
    "text": "Welcome to our Avalanche Hazard Prediction project.\n- Scientific Paper\n- LLM Reflection\n- Appendix\n Source: wallpapers.com"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "Appendix",
    "section": "",
    "text": "Data\nThe following table provides descriptions, datatypes, and basic distributional analysis for the dataset variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nData Type\nExample\nDefinition\nNA’s/Blanks\nMissing Percentage (%)\nMin\n1st Qu\nMedian\nMean\n3rd Qu\nMax\n\n\n\n\nDate\ndate\n17/12/2009 12:30\nThe date and time when the observation or forecast was recorded.\n0\n0\n-\n-\n-\n-\n-\n-\n\n\nArea\nchr\nCreag Meagaidh\nThe specific mountain region or forecast area in Scotland (e.g., Creag Meagaidh, Torridon).\n0\n0\n-\n-\n-\n-\n-\n-\n\n\nlongitude\nnum\n-0.392\nThe longitude coordinate of the observation location in decimal degrees.\n0\n0\n-1.2021\n-0.5424\n-0.4315\n-0.3984\n-0.2705\n0.5701\n\n\nlatitude\nnum\n2.22\nThe latitude coordinate of the observation location in decimal degrees.\n0\n0\n1.361\n1.982\n2.198\n2.298\n2.711\n3.08\n\n\nAlt\nint\n800\nAltitude of the observation site in meters above sea level.\n6\n0.05622716\n-1\n800\n910\n934\n1030\n244859\n\n\nAspect\nint\n160\nThe compass direction (in degrees) that the slope faces, relevant to avalanche risk.\n355\n3.3267735\n-1\n50\n90\n153.2\n225\n163770\n\n\nIncline\nint\n28\nThe slope angle (in degrees) where the observation was taken, critical for avalanche potential.\n36\n0.33736295\n-1\n22\n28\n26.76\n32\n1020\n\n\nObs\nchr\nWS\nObservation type or condition code (e.g., WS for Wet Snow, TR for Tracks), indicating snow or terrain state.\n21\n0.197795988\n-\n-\n-\n-\n-\n-\n\n\nFAH\nchr\nModerate\nForecast Avalanche Hazard, the predicted avalanche danger level for the next 24 hours.\n109\n1.026655364\n-\n-\n-\n-\n-\n-\n\n\nOAH\nchr\nModerate\nObserved Avalanche Hazard, the assessed avalanche danger based on current field observations.\n453\n4.266742018\n-\n-\n-\n-\n-\n-\n\n\nAir.Temp\nnum\n-3.2\nAir temperature (in °C) at the observation site, influencing snow stability.\n34\n0.31862056\n-10.8\n-2.1\n-0.2\n0.06021\n2.1\n17\n\n\nWind.Dir\nnum\n45\nWind direction (in degrees) affecting snow distribution and drift formation.\n158\n1.48064849\n-2.6\n150\n220\n202.1\n270\n905\n\n\nWind.Speed\nnum\n10\nWind speed (in km/h or mph), impacting snow transport and avalanche risk.\n53\n0.49667323\n-2\n8\n15\n16.34\n22\n290\n\n\nCloud\nint\n90\nCloud cover percentage, affecting temperature and precipitation patterns.\n29\n0.2717646\n-1\n70\n100\n80.21\n100\n199\n\n\nPrecip.Code\nchr\n2 - Trace\nPrecipitation code indicating type and intensity (e.g., snow, rain, trace).\n583\n5.491193369\n-\n-\n-\n-\n-\n-\n\n\nDrift\nint\n1\nIndicator of snow drifting (1 = present, 0 = absent), affecting stability.\n0\n0\n-\n-\n-\n-\n-\n-\n\n\nTotal.Snow.Depth\nint\n45\nTotal depth of snow cover (in cm) at the observation site.\n163\n1.52750445\n-1\n45\n70\n95.75\n118\n3000\n\n\nFoot.Pen\nnum\n0\nFoot penetration depth (in cm), indicating snowpack consistency.\n42\n0.3935901\n-1\n5\n10\n13.96\n20\n300\n\n\nSki.Pen\nint\nNA\nSki penetration depth (in cm), showing snowpack support for skiing.\n2404\n22.52834786\n-1\n0\n0\n0.5928\n0\n55\n\n\nRain.at.900\nint\n0\nRainfall at 900m altitude (in mm or binary indicator), affecting snow melt.\n0\n0\n0\n0\n0\n0.1912\n0\n1\n\n\nSummit.Air.Temp\nnum\nNA\nAir temperature (in °C) at the summit, influencing upper snowpack conditions.\n754\n7.06587949\n-13.4\n-3.6\n-1.3\n-1.24\n0.8\n15\n\n\nSummit.Wind.Dir\nint\nNA\nWind direction (in degrees) at the summit, impacting snow distribution.\n1318\n12.35123231\n-2\n160\n220\n200.1\n250\n2213\n\n\nSummit.Wind.Speed\nint\nNA\nWind speed (in km/h or mph) at the summit, affecting snow transport.\n909\n8.51841439\n-8\n14\n25\n27.89\n38\n360\n\n\nMax.Temp.Grad\nnum\n20\nMaximum temperature gradient (in °C) across the snowpack, indicating instability.\n710\n6.653547\n0\n0\n0.2\n1.211\n1\n130\n\n\nMax.Hardness.Grad\nint\n4\nMaximum hardness gradient within the snowpack, reflecting layer differences.\n629\n5.89448037\n0\n1\n2\n2.037\n3\n5\n\n\nNo.Settle\nint\nNA\nNumber of days since the last significant snowfall, affecting settlement.\n289\n2.70827476\n-1\n54\n128\n139.1\n206\n676\n\n\nSnow.Index\nint\nNA\nAn index or score related to snowpack stability or quality (specific method unclear).\n745\n6.98153875\n-1\n0\n0\n1.786\n0\n368\n\n\nInsolation\nint\nNA\nSolar radiation or insolation impact (in hours or intensity), affecting snow melt.\n507\n4.75119483\n-55\n3\n6\n7.594\n10\n208\n\n\nCrystals\nint\nNA\nType or size of snow crystals observed, influencing avalanche risk.\n988\n9.25873864\n-1\n0\n0\n1.45\n0\n15\n\n\nWetness\nint\nNA\nDegree of snow wetness (scale or percentage), impacting stability.\n576\n5.39780714\n-1\n1\n1\n1.414\n2\n10\n\n\nAV.Cat\nint\nNA\nAvalanche Category, likely a classification of avalanche type or severity.\n2494\n23.37175522\n-9999\n0\n0\n-321.7\n0\n8800\n\n\nSnow.Temp\nnum\nNA\nTemperature (in °C) within the snowpack, critical for stability assessment.\n410\n3.84218911\n-13.1\n-2.2\n-0.4\n-0.7149\n0\n124"
  },
  {
    "objectID": "llm-reflection.html",
    "href": "llm-reflection.html",
    "title": "LLM Usage and Reflection",
    "section": "",
    "text": "Our group extensively used multiple artificial intelligence tools throughout this avalanche prediction neural network project, employing a systematic and transparent approach to AI integration. The tools included Claude (Sonnet and Opus versions) by Anthropic, ChatGPT-5 by OpenAI and Grok (Grok 4) by xAI. All interactions were documented and archived in a dedicated Claude project for complete traceability1."
  },
  {
    "objectID": "llm-reflection.html#ai-statement",
    "href": "llm-reflection.html#ai-statement",
    "title": "LLM Usage and Reflection",
    "section": "",
    "text": "Our group extensively used multiple artificial intelligence tools throughout this avalanche prediction neural network project, employing a systematic and transparent approach to AI integration. The tools included Claude (Sonnet and Opus versions) by Anthropic, ChatGPT-5 by OpenAI and Grok (Grok 4) by xAI. All interactions were documented and archived in a dedicated Claude project for complete traceability1."
  },
  {
    "objectID": "llm-reflection.html#phases-of-ai-utilisation",
    "href": "llm-reflection.html#phases-of-ai-utilisation",
    "title": "LLM Usage and Reflection",
    "section": "Phases of AI Utilisation",
    "text": "Phases of AI Utilisation\nAI tools supported key stages of our data science workflow:\n\nExploratory Data Analysis (EDA): Assisted in identifying trends and patterns in the Scotland avalanche forecasts dataset.\nModel Development and Preprocessing: Provided guidance on handling missing data imputation, outlier detection/treatment, and class imbalance. Suggested methods included median imputation by geographic area for numerical variables, mode imputation by area for categorical variables, and context-specific outlier thresholds (e.g., capping altitude at Scotland’s highest peak of 1,345m).\nCode Development: Generated comprehensive R code using keras3 and TensorFlow, based on our EDA findings and requirements. Key prompts covered outlier assessment, missing value strategies, model architecture (including Random Forest feature selection and hyperparameter tuning via grid search), and data splitting (e.g., adjusting from 80/10/10 to 70/15/10 ratios). Also aided debugging, such as transitioning from manual upsampling to ROSE techniques.\nReport Writing and Review: Helped draft analysis sections, interpret evaluation metrics, and perform proofreading, spell-checking, and grammar verification.\n\nWe maintained critical oversight over the AI deliverables. All AI-generated content was verified against avalanche forecasting literature and Scottish meteorological standards, with code tested for functionality in our dataset context."
  },
  {
    "objectID": "llm-reflection.html#benefits-and-verification",
    "href": "llm-reflection.html#benefits-and-verification",
    "title": "LLM Usage and Reflection",
    "section": "Benefits and Verification",
    "text": "Benefits and Verification\nAI integration offered our group substantial advantages, including:\n\nAccelerated timelines and exposure to advanced techniques.\nComprehensive code documentation and creative problem-solving.\n\nAccuracy was verified through:\n\nCross-referencing with peer-reviewed research.\nSystematic code testing and manual spot-checks.\nComparing outputs across tools for inconsistencies.\nDomain-specific evaluation of methodologies."
  },
  {
    "objectID": "llm-reflection.html#critical-reflection",
    "href": "llm-reflection.html#critical-reflection",
    "title": "LLM Usage and Reflection",
    "section": "Critical Reflection",
    "text": "Critical Reflection\nAI tools demonstrated significant strengths but also limitations:\n\nAdvantages: Excelled in generating syntactically correct code and providing creative solutions, enhancing efficiency and innovation.\nLimitations: Occasionally suggested technically sound but contextually unsuitable approaches, lacking nuance in domain-specific factors (e.g., Scottish mountain meteorology). Different tools sometimes gave conflicting advice, requiring synthesis and judgment.\n\nUltimately, AI serves as a powerful assistant but cannot replace human critical thinking, domain expertise, or methodological rigor. This project highlighted the importance of thoughtful, transparent AI use to amplify capabilities while maintaining control."
  },
  {
    "objectID": "llm-reflection.html#llm-prompt-links",
    "href": "llm-reflection.html#llm-prompt-links",
    "title": "LLM Usage and Reflection",
    "section": "LLM prompt links",
    "text": "LLM prompt links\n\nChats from Claude\nEDA\nOutlier Analysis\nNaN analsis\nFeature Selection\nModel Development\nModel Development\nModel Debugging\n\n\nChats from Grok\nEDA and initial Model Development\nModel Refinement\nModel Debugging\nMarkdown format & Webpage hosting\n\n\nChats from ChatGPT"
  },
  {
    "objectID": "llm-reflection.html#footnotes",
    "href": "llm-reflection.html#footnotes",
    "title": "LLM Usage and Reflection",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nClaude projects on the Claude Pro plan cannot be made available to the public (projects can be shared publicly on the Enterprise plan). However, links to the individual chats can be shared publicly. A sample of chats are shared below in the LLM prompt links section.↩︎"
  }
]